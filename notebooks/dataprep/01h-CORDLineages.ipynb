{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloads Publication Information for PANGO Lineages from the CORD-19 Data Set\n",
    "**[Work in progress]**\n",
    "\n",
    "This notebook text-mines [PANGO lineage](https://cov-lineages.org/) mentions in the titles and abstracts of publications and preprints from the CORD-19 data set. Note, the text-mined results may contain false positive!\n",
    "\n",
    "Data sources: [PANGO Lineage Designations](https://github.com/cov-lineages/pango-designation), \n",
    "[CORD-19](https://allenai.org/data/cord-19)\n",
    "\n",
    "References:\n",
    "\n",
    "Rambaut A, et al., A dynamic nomenclature proposal for SARS-CoV-2 lineages to assist genomic epidemiology(2020) Nature Microbiology [doi:10.1038/s41564-020-0770-5](https://doi.org/10.1038/s41564-020-0770-5).\n",
    "\n",
    "Lucy Lu Wang, et al., CORD-19: The COVID-19 Open Research Dataset (2020) [arXiv:2004.10706v4](https://arxiv.org/abs/2004.10706).\n",
    "\n",
    "Author: Peter Rose (pwrose@ucsd.edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import io\n",
    "import dateutil\n",
    "import re\n",
    "from pathlib import Path\n",
    "import nltk\n",
    "import json, requests\n",
    "from urllib.request import urlopen\n",
    "from xml.etree.ElementTree import parse\n",
    "import urllib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = None  # display all rows\n",
    "pd.options.display.max_columns = None  # display all columsns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lyt/Library/Application Support/Neo4j Desktop/Application/relate-data/dbmss/dbms-a1516f46-b63a-46dd-b67a-1fb59d6c5d05/import\n"
     ]
    }
   ],
   "source": [
    "NEO4J_IMPORT = \"/Users/lyt/Library/Application Support/Neo4j Desktop/Application/relate-data/dbmss/dbms-a1516f46-b63a-46dd-b67a-1fb59d6c5d05/import\"#Path(os.getenv('NEO4J_IMPORT'))\n",
    "print(NEO4J_IMPORT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get PANGO lineages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pango = pd.read_csv(NEO4J_IMPORT + \"/00b-PANGOLineage.csv\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lineage</th>\n",
       "      <th>description</th>\n",
       "      <th>alias</th>\n",
       "      <th>predecessor</th>\n",
       "      <th>l0</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>l3</th>\n",
       "      <th>levels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>BA.1.17.2</td>\n",
       "      <td>Alias of B.1.1.529.1.17.2, lineage from pango-...</td>\n",
       "      <td>B.1.1.529.1.17.2</td>\n",
       "      <td>B.1.1.529.1.17</td>\n",
       "      <td>BA.1.17.2</td>\n",
       "      <td>BA.1.17</td>\n",
       "      <td>BA.1</td>\n",
       "      <td>BA</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>B.1.1.153</td>\n",
       "      <td>Northern European Lineage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B.1.1.153</td>\n",
       "      <td>B.1.1</td>\n",
       "      <td>B.1</td>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>AA.6</td>\n",
       "      <td>Alias of B.1.177.15.6, Welsh Lineage</td>\n",
       "      <td>B.1.177.15.6</td>\n",
       "      <td>B.1.177.15</td>\n",
       "      <td>AA.6</td>\n",
       "      <td>AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>B.1.564.1</td>\n",
       "      <td>Canada lineage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B.1.564.1</td>\n",
       "      <td>B.1.564</td>\n",
       "      <td>B.1</td>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>B.1.505</td>\n",
       "      <td>Israel and england (was B.1.3.4)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B.1.505</td>\n",
       "      <td>B.1</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lineage                                        description  \\\n",
       "631   BA.1.17.2  Alias of B.1.1.529.1.17.2, lineage from pango-...   \n",
       "250   B.1.1.153                          Northern European Lineage   \n",
       "807        AA.6               Alias of B.1.177.15.6, Welsh Lineage   \n",
       "1258  B.1.564.1                                     Canada lineage   \n",
       "1202    B.1.505                   Israel and england (was B.1.3.4)   \n",
       "\n",
       "                 alias     predecessor         l0       l1    l2   l3 levels  \n",
       "631   B.1.1.529.1.17.2  B.1.1.529.1.17  BA.1.17.2  BA.1.17  BA.1   BA      4  \n",
       "250                NaN             NaN  B.1.1.153    B.1.1   B.1    B      4  \n",
       "807       B.1.177.15.6      B.1.177.15       AA.6       AA   NaN  NaN      2  \n",
       "1258               NaN             NaN  B.1.564.1  B.1.564   B.1    B      4  \n",
       "1202               NaN             NaN    B.1.505      B.1     B  NaN      3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pango.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineages = pango['lineage'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1668"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lineages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get max number of dots in lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "f = lambda x: x.count('.')\n",
    "f = np.vectorize(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(f(lineages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get CORD-19 Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE = Path(NEO4J_IMPORT +'/cache/cord19/2022-03-31/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(CACHE, dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/covid-19-community/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype={value.dtype})\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "metadata.fillna('', inplace=True)\n",
    "#convert datetime column to just date\n",
    "metadata['year'] = metadata['publish_time'].apply(lambda d: d[:4] if len(d) > 4 else '')\n",
    "metadata['date'] = metadata['publish_time'].apply(lambda d: dateutil.parser.parse(d) if len(d) > 0 else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of papers 992921\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of papers\", metadata.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract a list of PANGO lineages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove special characters to simply parsing for lineages in parenthesis, comma-separated lists, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['title'] = metadata['title'].replace('[()/,]', ' ', regex=True)\n",
    "metadata['abstract'] = metadata['abstract'].replace('[()/,]', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match PANGO patterns and check agains list of known lineages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = re.compile(' [A-Z]{1,2}[.]\\d+ ')\n",
    "pattern2 = re.compile(' [A-Z]{1,2}[.]\\d+[.]\\d+ ')\n",
    "pattern3 = re.compile(' [A-Z]{1,2}[.]\\d+[.]\\d+[.]+\\d+ ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lineages(row):\n",
    "    text = ' ' + row.title + ' ' + row.abstract + ' '\n",
    "    lin = pattern1.findall(text) + pattern2.findall(text) + pattern3.findall(text)\n",
    "    u_lin = set()\n",
    "    \n",
    "    \n",
    "    \n",
    "    for l in lin:\n",
    "        l = l.strip()\n",
    "        # check if lineage is valid (e.g., not a withdrawn lineage or false positive)\n",
    "        if l in lineages:\n",
    "            u_lin.add(l)\n",
    "            \n",
    "    return \";\".join(u_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sample subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = metadata.sample(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lineages'] = data.apply(get_lineages, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep those has lineage in title & abstract\n",
    "ln = data[data['lineages'].str.len() > 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B.1.1.7'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln.iloc[3].lineages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We report three cases of SARS-CoV-2 lineage B.1.1.7 infection in Malayan tigers at the Virginia Zoo. All three animals exhibited respiratory signs. These findings show the mutations in the B.1.1.7 lineage did not affect the susceptibility of tigers to SARS-CoV-2.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln.iloc[3].abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['lineages'] = metadata.apply(get_lineages, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only papers that map to PANGO lineages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = metadata[metadata['lineages'].str.len() > 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign CURIEs from [Identifiers.org](https://identifiers.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits['doi'] = hits['doi'].apply(lambda x: 'doi:' + x if len(x) > 0 else '')\n",
    "hits['pubmed_id'] = hits['pubmed_id'].apply(lambda x: 'pubmed:' + x if len(x) > 0 else '')\n",
    "hits['pmcid'] = hits['pmcid'].apply(lambda x: 'pmc:' + x if len(x) > 0 else '')\n",
    "hits['arxiv_id'] = hits['arxiv_id'].apply(lambda x: 'arxiv:' + x if len(x) > 0 else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hits.sort_values(by=['publish_time'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches 4419\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of matches\", hits.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_id(row):\n",
    "    \"\"\"Creates a unique id using the most commonly available id in priority order\"\"\"\n",
    "    if row.doi != '':\n",
    "        return row.doi\n",
    "    elif row.pubmed_id != '':\n",
    "        return row.pubmed_id\n",
    "    elif row.pmcid != '':\n",
    "        return row.pmcid\n",
    "    elif row.arxiv_id != '':\n",
    "        return row.arxiv_id\n",
    "    elif row.url != '':\n",
    "        return row.url\n",
    "    else:\n",
    "        # TODO deal with WHO papers here?\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits['id'] = hits.apply(create_id, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHO documents seem to be copies of articles that are already present in the dataset and will be ignored for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits.query('id != \"\"', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of matches 3200\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of matches\", hits.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits.to_csv(NEO4J_IMPORT + \"01h-CORDLineages.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fulltext Regrex\n",
    "1. How to save body paragraph texts? Save as a dataframe with id & content to Neo4j?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get articles ids for specific lineage\n",
    "\n",
    "def get_ids(lineage):\n",
    "    url = requests.get(f'https://www.ebi.ac.uk/europepmc/webservices/rest/search?query=(%22{lineage}%22%20AND%20(%22SARS-CoV-2%22%20OR%20%22COVID-19%22)%20AND%20(%22lineage%22%20OR%20%22lineages%22%20OR%20%22strain%22%20OR%20%22strains%22%20OR%20%22variants%22%20OR%20%22variants%22))%20AND%20(FIRST_PDATE:%5b2020-01-01%20)%20AND%20HAS_FT:y%20AND%20%20sort_date:y&resultType=idlist&pageSize=1000&format=json&cursorMark=*')\n",
    "    text = url.text\n",
    "    results = json.loads(text)['resultList']['result']\n",
    "    ids = list(map(lambda x: x['fullTextIdList']['fullTextId'][0], results))\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download articles in XML and return body paragraph\n",
    "def download_article(article_id):\n",
    "    url = f'https://www.ebi.ac.uk/europepmc/webservices/rest/{article_id}/fullTextXML'\n",
    "    xmldoc = parse(urlopen(url))\n",
    "    \n",
    "    # get full text\n",
    "    root = xmldoc.getroot()\n",
    "    text = root.findall('.//p')\n",
    "\n",
    "    # put body paragraphs together\n",
    "    ptext = \"\"\n",
    "    for p in text:\n",
    "        ptext += ''.join([x for x in p.itertext()]) + '.\\n' + '\\n'\n",
    "    return ptext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lineage for full texts\n",
    "def get_full_lineage(ptext):\n",
    "    # tokenize texts into sentences\n",
    "    p_sentence = nltk.tokenize.sent_tokenize(ptext)\n",
    "    \n",
    "    # record lineages\n",
    "    record = []\n",
    "    for s in p_sentence:\n",
    "        s1 = re.subn('[()/,]', ' ', s)[0] # remove special chars\n",
    "        lin = pattern1.findall(s1) + pattern2.findall(s1) + pattern3.findall(s1)\n",
    "\n",
    "        if lin: # if find lineages record sentence\n",
    "            record.append([lin, s])\n",
    "    return record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test on B.1.1.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something went wrong.\n",
      "Something went wrong.\n",
      "Something went wrong.\n",
      "Something went wrong.\n",
      "Something went wrong.\n",
      "Something went wrong.\n",
      "Something went wrong.\n",
      "Something went wrong.\n",
      "Something went wrong.\n",
      "Something went wrong.\n",
      "Something went wrong.\n"
     ]
    }
   ],
   "source": [
    "lineage = 'B.1.1.7'\n",
    "ids = get_ids(lineage)\n",
    "\n",
    "full_regrex = []\n",
    "for i in ids:\n",
    "    try: \n",
    "        body_text = download_article(i)\n",
    "        record = get_full_lineage(body_text)\n",
    "        # attach article id to lineage record\n",
    "        [x.append(i) for x in record]\n",
    "        full_regrex.append(pd.DataFrame(record))\n",
    "    except urllib.error.HTTPError as exc:\n",
    "        print('Something went wrong.')\n",
    "        time.sleep(10) # wait 10 seconds and then make http request again\n",
    "        continue\n",
    "\n",
    "fulltext_lineage = pd.concat(full_regrex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulltext_lineage.to_csv('B_1_1_7.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test on P.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something went wrong.\n",
      "Something went wrong.\n",
      "Something went wrong.\n",
      "Something went wrong.\n",
      "Something went wrong.\n",
      "Something went wrong.\n",
      "Something went wrong.\n",
      "Something went wrong.\n",
      "Something went wrong.\n",
      "Something went wrong.\n",
      "Something went wrong.\n",
      "Something went wrong.\n",
      "Something went wrong.\n",
      "Something went wrong.\n"
     ]
    }
   ],
   "source": [
    "lineage = 'P.1'\n",
    "ids = get_ids(lineage)\n",
    "\n",
    "full_regrex = []\n",
    "for i in ids:\n",
    "    try: \n",
    "        body_text = download_article(i)\n",
    "        record = get_full_lineage(body_text)\n",
    "        # attach article id to lineage record\n",
    "        [x.append(i) for x in record]\n",
    "        full_regrex.append(pd.DataFrame(record))\n",
    "    except urllib.error.HTTPError as exc:\n",
    "        print('Something went wrong.')\n",
    "        time.sleep(10) # wait 10 seconds and then make http request again\n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulltext_lineage_p1 = pd.concat(full_regrex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulltext_lineage_p1.to_csv('P_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
