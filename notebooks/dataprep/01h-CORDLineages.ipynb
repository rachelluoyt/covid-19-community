{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloads Publication Information for PANGO Lineages from the CORD-19 Data Set\n",
    "**[Work in progress]**\n",
    "\n",
    "This notebook text-mines [PANGO lineage](https://cov-lineages.org/) mentions in the titles and abstracts of publications and preprints from the CORD-19 data set. Note, the text-mined results may contain false positive!\n",
    "\n",
    "Data sources: [PANGO Lineage Designations](https://github.com/cov-lineages/pango-designation), \n",
    "[CORD-19](https://allenai.org/data/cord-19)\n",
    "\n",
    "References:\n",
    "\n",
    "Rambaut A, et al., A dynamic nomenclature proposal for SARS-CoV-2 lineages to assist genomic epidemiology(2020) Nature Microbiology [doi:10.1038/s41564-020-0770-5](https://doi.org/10.1038/s41564-020-0770-5).\n",
    "\n",
    "Lucy Lu Wang, et al., CORD-19: The COVID-19 Open Research Dataset (2020) [arXiv:2004.10706v4](https://arxiv.org/abs/2004.10706).\n",
    "\n",
    "Author: Peter Rose (pwrose@ucsd.edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import io\n",
    "import dateutil\n",
    "import re\n",
    "from pathlib import Path\n",
    "import nltk\n",
    "import json, requests\n",
    "from urllib.request import urlopen\n",
    "from xml.etree.ElementTree import parse\n",
    "import urllib\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = None  # display all rows\n",
    "pd.options.display.max_columns = None  # display all columsns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lyt/Library/Application Support/Neo4j Desktop/Application/relate-data/dbmss/dbms-a1516f46-b63a-46dd-b67a-1fb59d6c5d05/import\n"
     ]
    }
   ],
   "source": [
    "NEO4J_IMPORT = \"/Users/lyt/Library/Application Support/Neo4j Desktop/Application/relate-data/dbmss/dbms-a1516f46-b63a-46dd-b67a-1fb59d6c5d05/import\"#Path(os.getenv('NEO4J_IMPORT'))\n",
    "print(NEO4J_IMPORT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get PANGO lineages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "pango = pd.read_csv(NEO4J_IMPORT + \"/00b-PANGOLineage.csv\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lineage</th>\n",
       "      <th>description</th>\n",
       "      <th>alias</th>\n",
       "      <th>predecessor</th>\n",
       "      <th>l0</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>l3</th>\n",
       "      <th>levels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>B.1.1.424</td>\n",
       "      <td>Russia lineage, contains some formally B.1.1.1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B.1.1.424</td>\n",
       "      <td>B.1.1</td>\n",
       "      <td>B.1</td>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>U.1</td>\n",
       "      <td>Alias of B.1.177.60.1, England</td>\n",
       "      <td>B.1.177.60.1</td>\n",
       "      <td>B.1.177.60</td>\n",
       "      <td>U.1</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>AZ.6</td>\n",
       "      <td>Alias of B.1.1.318.6, Canada lineage, from pan...</td>\n",
       "      <td>B.1.1.318.6</td>\n",
       "      <td>B.1.1.318</td>\n",
       "      <td>AZ.6</td>\n",
       "      <td>AZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>B.1.177.80</td>\n",
       "      <td>Scandinavian lineage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B.1.177.80</td>\n",
       "      <td>B.1.177</td>\n",
       "      <td>B.1</td>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>B.1.177.57</td>\n",
       "      <td>UK lineage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B.1.177.57</td>\n",
       "      <td>B.1.177</td>\n",
       "      <td>B.1</td>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lineage                                        description  \\\n",
       "528   B.1.1.424  Russia lineage, contains some formally B.1.1.1...   \n",
       "924         U.1                     Alias of B.1.177.60.1, England   \n",
       "422        AZ.6  Alias of B.1.1.318.6, Canada lineage, from pan...   \n",
       "945  B.1.177.80                               Scandinavian lineage   \n",
       "920  B.1.177.57                                         UK lineage   \n",
       "\n",
       "            alias predecessor          l0       l1   l2   l3 levels  \n",
       "528           NaN         NaN   B.1.1.424    B.1.1  B.1    B      4  \n",
       "924  B.1.177.60.1  B.1.177.60         U.1        U  NaN  NaN      2  \n",
       "422   B.1.1.318.6   B.1.1.318        AZ.6       AZ  NaN  NaN      2  \n",
       "945           NaN         NaN  B.1.177.80  B.1.177  B.1    B      4  \n",
       "920           NaN         NaN  B.1.177.57  B.1.177  B.1    B      4  "
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pango.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineages = pango['lineage'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = re.compile(' [A-Z]{1,2}[.]\\d+ ', re.IGNORECASE)\n",
    "pattern2 = re.compile(' [A-Z]{1,2}[.]\\d+[.]\\d+ ', re.IGNORECASE)\n",
    "pattern3 = re.compile(' [A-Z]{1,2}[.]\\d+[.]\\d+[.]+\\d+ ', re.IGNORECASE)\n",
    "\n",
    "# add WHO lineage\n",
    "who_lineage = [' Alpha ', ' Beta ', ' Gamma ', ' Epsilon ',' Zeta ', ' Eta ', ' Theta  ',\\\n",
    "               ' Iota ', ' Kappa ', ' Lambda ', ' Mu ']\n",
    "pattern4 = re.compile(\"|\".join(who_lineage), re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add who to lineages\n",
    "lineages = np.append(lineages, who_lineage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Get CORD-19 Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE = Path(NEO4J_IMPORT +'/cache/cord19/2022-03-31/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(CACHE, dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.fillna('', inplace=True)\n",
    "#convert datetime column to just date\n",
    "metadata['year'] = metadata['publish_time'].apply(lambda d: d[:4] if len(d) > 4 else '')\n",
    "metadata['date'] = metadata['publish_time'].apply(lambda d: dateutil.parser.parse(d) if len(d) > 0 else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of papers\", metadata.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Extract a list of PANGO lineages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove special characters to simply parsing for lineages in parenthesis, comma-separated lists, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['title'] = metadata['title'].replace('[()/,]', ' ', regex=True)\n",
    "metadata['abstract'] = metadata['abstract'].replace('[()/,]', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match PANGO patterns and check agains list of known lineages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = re.compile(' [A-Z]{1,2}[.]\\d+ ', re.IGNORECASE)\n",
    "pattern2 = re.compile(' [A-Z]{1,2}[.]\\d+[.]\\d+ ', re.IGNORECASE)\n",
    "pattern3 = re.compile(' [A-Z]{1,2}[.]\\d+[.]\\d+[.]+\\d+ ', re.IGNORECASE)\n",
    "\n",
    "# add WHO lineage\n",
    "who_lineage = [' Alpha ', ' Beta ', ' Gamma ', ' Epsilon ',' Zeta ', ' Eta ', ' Theta  ',\\\n",
    "               ' Iota ', ' Kappa ', ' Lambda ', ' Mu ']\n",
    "pattern4 = re.compile(\"|\".join(who_lineage), re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add who to lineages\n",
    "lineages = np.append(lineages, who_lineage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lineages(row):\n",
    "    text = ' ' + row.title + ' ' + row.abstract + ' '\n",
    "    lin = pattern1.findall(text) + pattern2.findall(text) + pattern3.findall(text)\n",
    "    u_lin = set()\n",
    "    \n",
    "    \n",
    "    for l in lin:\n",
    "        l = l.strip()\n",
    "        # check if lineage is valid (e.g., not a withdrawn lineage or false positive)\n",
    "        if l in lineages:\n",
    "            u_lin.add(l)\n",
    "            \n",
    "    return \";\".join(u_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run on whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['lineages'] = metadata.apply(get_lineages, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only papers that map to PANGO lineages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = metadata[metadata['lineages'].str.len() > 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign CURIEs from [Identifiers.org](https://identifiers.org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits['doi'] = hits['doi'].apply(lambda x: 'doi:' + x if len(x) > 0 else '')\n",
    "hits['pubmed_id'] = hits['pubmed_id'].apply(lambda x: 'pubmed:' + x if len(x) > 0 else '')\n",
    "hits['pmcid'] = hits['pmcid'].apply(lambda x: 'pmc:' + x if len(x) > 0 else '')\n",
    "hits['arxiv_id'] = hits['arxiv_id'].apply(lambda x: 'arxiv:' + x if len(x) > 0 else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hits.sort_values(by=['publish_time'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches 4419\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of matches\", hits.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_id(row):\n",
    "    \"\"\"Creates a unique id using the most commonly available id in priority order\"\"\"\n",
    "    if row.doi != '':\n",
    "        return row.doi\n",
    "    elif row.pubmed_id != '':\n",
    "        return row.pubmed_id\n",
    "    elif row.pmcid != '':\n",
    "        return row.pmcid\n",
    "    elif row.arxiv_id != '':\n",
    "        return row.arxiv_id\n",
    "    elif row.url != '':\n",
    "        return row.url\n",
    "    else:\n",
    "        # TODO deal with WHO papers here?\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits['id'] = hits.apply(create_id, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHO documents seem to be copies of articles that are already present in the dataset and will be ignored for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits.query('id != \"\"', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of matches 3200\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of matches\", hits.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits.to_csv(NEO4J_IMPORT + \"01h-CORDLineages.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fulltext Regrex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get articles ids for specific lineage\n",
    "def get_ids(lineage):\n",
    "    url = requests.get(f'https://www.ebi.ac.uk/europepmc/webservices/rest/search?query=(%22{lineage}%22%20AND%20(%22SARS-CoV-2%22%20OR%20%22COVID-19%22)%20AND%20(%22lineage%22%20OR%20%22lineages%22%20OR%20%22strain%22%20OR%20%22strains%22%20OR%20%22variants%22%20OR%20%22variants%22))%20AND%20(FIRST_PDATE:%5b2020-01-01%20)%20AND%20HAS_FT:y%20AND%20%20sort_date:y&resultType=idlist&pageSize=1000&format=json&cursorMark=*')\n",
    "    text = url.text\n",
    "    results = json.loads(text)['resultList']['result']\n",
    "    ids = list(map(lambda x: x['fullTextIdList']['fullTextId'][0], results))\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download articles in XML and return body paragraph\n",
    "def download_article(article_id):\n",
    "    url = f'https://www.ebi.ac.uk/europepmc/webservices/rest/{article_id}/fullTextXML'\n",
    "    xmldoc = parse(urlopen(url))\n",
    "    \n",
    "    # get full text\n",
    "    root = xmldoc.getroot()\n",
    "    text = root.findall('.//p')\n",
    "\n",
    "    # put body paragraphs together\n",
    "    ptext = \"\"\n",
    "    for p in text:\n",
    "        ptext += ''.join([x for x in p.itertext()]) + '.\\n' + '\\n'\n",
    "    return ptext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lineage for full texts\n",
    "def get_full_lineage(ptext):\n",
    "    # tokenize texts into sentences\n",
    "    p_sentence = nltk.tokenize.sent_tokenize(ptext)\n",
    "    \n",
    "    # record lineages\n",
    "    linset = set()\n",
    "    pair = []\n",
    "    for s in p_sentence:\n",
    "        s1 = re.subn('[()/,]', ' ', s)[0] # remove special chars\n",
    "        lin = set(pattern1.findall(s1) + pattern2.findall(s1) + pattern3.findall(s1) + pattern4.findall(s1))\n",
    "\n",
    "        if lin: \n",
    "            for l in lin:\n",
    "                # valid lineage and not recorded\n",
    "                l = l.strip()\n",
    "                l = l.capitalize()\n",
    "                if (l in lineages) and (l not in linset): \n",
    "                    linset.add(l)\n",
    "                    pair.append([l, s])\n",
    "                else: continue\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    ptext = re.subn('[()/,]', ' ', ptext)[0] # remove special chars\n",
    "    lin = pattern1.findall(ptext) + pattern2.findall(ptext) + pattern3.findall(ptext)\n",
    "    lin_set = set(lin)\n",
    "    \n",
    "    record = []\n",
    "    if lin_set:\n",
    "        for l in lin_set:\n",
    "            \n",
    "            sen = re.search(r\"\\.?([^\\.]*{}[^\\.]*)\".format(l), ptext).group()\n",
    "            record.append([l, sen])\n",
    "    \"\"\"\n",
    "    return pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap up function take lineage as input and output dataframe\n",
    "def extract_full(lineage):\n",
    "    ids = get_ids(lineage)\n",
    "    full_regrex = []\n",
    "    if ids:\n",
    "        for i in ids:\n",
    "            try: \n",
    "                path = Path(f'{lineage}/{i}.txt')\n",
    "\n",
    "                # if file not exist, get body text and save to file\n",
    "                if not path.is_file():\n",
    "                    body_text = download_article(i)\n",
    "                    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                    with path.open(\"w\", encoding =\"utf-8\") as f:\n",
    "                        f.write(body_text)\n",
    "                        f.close()\n",
    "                else: # otherwise retrieve text\n",
    "                    body_text = path.read_text()\n",
    "\n",
    "                record = get_full_lineage(body_text) # get lineages\n",
    "                [x.append(i) for x in record] # attach article id to lineage record\n",
    "                full_regrex.append(pd.DataFrame(record))\n",
    "            except urllib.error.HTTPError as exc:\n",
    "                time.sleep(10) # wait 10 seconds and then make http request again\n",
    "                continue\n",
    "        df_fulltext = pd.concat(full_regrex)\n",
    "        return df_fulltext\n",
    "    else: return None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### test on B.1.1.7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineage = 'B.1.1.7'\n",
    "ids = get_ids(lineage)\n",
    "\n",
    "full_regrex = []\n",
    "for i in ids:\n",
    "    try: \n",
    "        path = Path(f'{lineage}/{i}.txt')\n",
    "        \n",
    "        # if file not exist, get body text and save to file\n",
    "        if not path.is_file():\n",
    "            body_text = download_article(i)\n",
    "            path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            with path.open(\"w\", encoding =\"utf-8\") as f:\n",
    "                f.write(body_text)\n",
    "                f.close()\n",
    "        else: # otherwise retrieve text\n",
    "            body_text = path.read_text()\n",
    "        \n",
    "        \n",
    "        record = get_full_lineage(body_text) # get lineages\n",
    "        [x.append(i) for x in record] # attach article id to lineage record\n",
    "        full_regrex.append(pd.DataFrame(record))\n",
    "    except urllib.error.HTTPError as exc:\n",
    "        time.sleep(10) # wait 10 seconds and then make http request again\n",
    "        continue\n",
    "\n",
    "fulltext_lineage = pd.concat(full_regrex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulltext_lineage.to_csv('B_1_1_7.csv',index=False, header = ['lineage', 'string contains lineage', 'ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### test on P.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineage = 'P.1'\n",
    "ids = get_ids(lineage)\n",
    "\n",
    "full_regrex = []\n",
    "for i in ids:\n",
    "    try: \n",
    "        path = Path(f'{lineage}/{i}.txt')\n",
    "        \n",
    "        # if file not exist, get body text and save to file\n",
    "        if not path.is_file():\n",
    "            body_text = download_article(i)\n",
    "            path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            with path.open(\"w\", encoding =\"utf-8\") as f:\n",
    "                f.write(body_text)\n",
    "                f.close()\n",
    "        else: # otherwise retrieve text\n",
    "            body_text = path.read_text()\n",
    "        \n",
    "        \n",
    "        record = get_full_lineage(body_text) # get lineages\n",
    "        [x.append(i) for x in record] # attach article id to lineage record\n",
    "        full_regrex.append(pd.DataFrame(record))\n",
    "    except urllib.error.HTTPError as exc:\n",
    "        time.sleep(10) # wait 10 seconds and then make http request again\n",
    "        continue\n",
    "\n",
    "fulltext_lineage = pd.concat(full_regrex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulltext_lineage.to_csv('P_1.csv',index=False, header = ['lineage', 'string contains lineage', 'ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### manual check possible false postives\n",
    "#### B.1.1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "b117 = pd.read_csv('B_1_1_7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "b117 = b117.drop(['Unnamed: 0'],axis = 1)\n",
    "b117.columns = ['lineage', 'string contains lineage', 'ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. same sentence with many lineages are counted as positive, we remove those \n",
    "b117_sub = b117[~ b117.duplicated('string contains lineage',keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. extract articles with only one lineage, which are possibly FP\n",
    "IDs = b117_sub.groupby('ID').lineage.count().loc[lambda p : p == 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "b117_sub = b117_sub.set_index('ID').loc[IDs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual check\n",
    "#print(b117_sub['string contains lineage'].str.cat(sep = '\\n '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = pd.read_csv(\"P_1.csv\")\n",
    "p1_sub = p1[~ p1.duplicated('string contains lineage',keep=False)]\n",
    "IDs_1 = p1_sub.groupby('ID').lineage.count().loc[lambda p : p == 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_sub = p1_sub.set_index('ID').loc[IDs_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lineage</th>\n",
       "      <th>string contains lineage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PPR282435</th>\n",
       "      <td>R.9.4.1</td>\n",
       "      <td>The nucleic acid was converted to cDNA and amp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             lineage                            string contains lineage\n",
       "ID                                                                     \n",
       "PPR282435   R.9.4.1   The nucleic acid was converted to cDNA and amp..."
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1_sub[p1_sub['string contains lineage'].str.contains('The nucleic acid')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove A B\n",
    "lineages = np.delete(lineages, np.where(lineages == 'A'))\n",
    "lineages = np.delete(lineages, np.where(lineages == 'B'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def iter_lineage(lineage):\n",
    "    for l_ in lineage:\n",
    "        print(f'start {l_}')\n",
    "        '''if Path(f'{l_}/{l_}_df').is_file():\n",
    "            found.add(l_)\n",
    "            continue'''\n",
    "        if l_ == 'B.1.1.7' or l_ == 'P.1':\n",
    "            continue\n",
    "        start = time.time()\n",
    "        df = extract_full(l_)\n",
    "        if df is None: \n",
    "            print(f'nothing for {l_}')\n",
    "            nothing.add(l_)\n",
    "        else:\n",
    "            found.add(l_)\n",
    "            df.to_csv(f'{l_}/{l_}_df',index=False, \\\n",
    "                                        header = ['lineage', 'string contains lineage', 'ID'])\n",
    "            end = time.time()\n",
    "            print(f'done with {l_}, time duration --- seconds --- {end - start} \\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A.1', 'A.2', 'A.2.2', 'A.2.3', 'A.2.4', 'A.2.5', 'A.2.5.1',\n",
       "       'A.2.5.2', 'A.2.5.3', 'A.3'], dtype=object)"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_10 = lineages[:10]\n",
    "l_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start A.1\n",
      "done with A.1, time duration --- seconds --- 259.9149000644684 \n",
      "\n",
      "start A.2\n",
      "done with A.2, time duration --- seconds --- 195.07675504684448 \n",
      "\n",
      "start A.2.2\n",
      "done with A.2.2, time duration --- seconds --- 72.12044787406921 \n",
      "\n",
      "start A.2.3\n",
      "done with A.2.3, time duration --- seconds --- 12.405742168426514 \n",
      "\n",
      "start A.2.4\n",
      "done with A.2.4, time duration --- seconds --- 1.5441129207611084 \n",
      "\n",
      "start A.2.5\n",
      "done with A.2.5, time duration --- seconds --- 104.74268698692322 \n",
      "\n",
      "start A.2.5.1\n",
      "done with A.2.5.1, time duration --- seconds --- 0.9085829257965088 \n",
      "\n",
      "start A.2.5.2\n",
      "done with A.2.5.2, time duration --- seconds --- 1.22562575340271 \n",
      "\n",
      "start A.2.5.3\n",
      "done with A.2.5.3, time duration --- seconds --- 0.8530848026275635 \n",
      "\n",
      "start A.3\n",
      "done with A.3, time duration --- seconds --- 216.7770800590515 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "nothing = set()\n",
    "found = set()\n",
    "iter_lineage(l_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start J.1\n",
      "done with J.1, time duration --- seconds --- 177.6583170890808 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "iter_lineage(['J.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
