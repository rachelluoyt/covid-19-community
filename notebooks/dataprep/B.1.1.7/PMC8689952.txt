Francesco Napolitano and Xiaopeng Xu authors contributed equally to this work..

SARS-CoV-2 caused the first severe pandemic of the digital era. Computational approaches have been ubiquitously used in an attempt to timely and effectively cope with the resulting global health crisis. In order to extensively assess such contribution, we collected, categorized and prioritized over 17 000 COVID-19-related research articles including both peer-reviewed and preprint publications that make a relevant use of computational approaches. Using machine learning methods, we identified six broad application areas i.e. Molecular Pharmacology and Biomarkers, Molecular Virology, Epidemiology, Healthcare, Clinical Medicine and Clinical Imaging. We then used our prioritization model as a guidance through an extensive, systematic review of the most relevant studies. We believe that the remarkable contribution provided by computational applications during the ongoing pandemic motivates additional efforts toward their further development and adoption, with the aim of enhancing preparedness and critical response for current and future emergencies..

The ongoing COVID-19 pandemic has prompted an unprecedented research effort by the global scientific community. The urge to identify effective countermeasures against the tremendous health, economic and social impact caused by the disease led to an astounding proliferation of studies covering all the diverse aspects of the pandemic [42]. From the development of assays aimed at better understanding, the molecular mechanisms exploited by the virus to the design of epidemiological models predicting its spread, research labs around the world have produced a sheer amount of potentially fruitful knowledge, which is still growing on a daily basis at a soaring pace while we write..

COVID-19 is also the first severe pandemic of the digital era. Besides accelerating the production and spread of research literature, digital technologies produced a significant impact as investigational tools, with contributions that range from the viral sequence establishment [173] to the latest data-driven risk models that are helping governments to select the most efficient restriction measures [26]. Such results are already summarized by a number of review articles, which cover both specific application areas (like drug discovery and repositioning [108, 116, 167], preventive pharmacology [106], medical image analysis [110]) and method-oriented overviews, such as artificial intelligence (AI) applications [85, 88] and relevant software tools [73]..

As valuable as these efforts are, the quantity of published studies poses a significant challenge both for researchers and for media operators striving to remain up to date with the state-of-art, and correctly inform the governments and the public. The emergency character of a pandemic crisis urges researchers to make their results timely available. In this regard, online platforms for preprint publication provide an effective shortcut [158], although the lack of a peer-review process warrants additional caution [22]. In general, the usual time span needed by the scientific community to properly digest the available literature and reach a consensus on the most promising research directions is challenged by the number of publications made available in such a short amount of time..

CSCoV data collection and analysis pipeline. COVID-19 related scientific papers are collected by querying 4 different sources, including both journal (PubMed) and preprint articles (arXiv, bioRxiv, medRxiv). The database of computational studies (CSCoV) is obtained by filtering the collected COVID-19 papers based on a manually curated set of 83 keywords to be matched against the article abstracts. The dataset of computational papers is then analyzed using a topic modeling method for categorization and a machine learning model together with bibliometric-based ranking for prioritization. The latter is based on additional quality metrics obtained from the Semantic Scholar website or from preprint servers..

For these reasons, with the aim of comprehensively assessing the contribution provided by computational applications in the fight against the ongoing pandemic, we developed a software framework called computational studies about COVID-19 (CSCoV) based on automatic collection and filtering of computational studies related to COVID-19. The framework automatically gathers both articles from multiple sources and meta-data about publication and author metrics in order to prioritize the studies by predicted relevance. AI is then used to categorize the papers by topics and to predict the chances of preprint articles to pass a peer-review process. The whole framework is continuously updated with new articles and corresponding metrics. With the help of the CSCoV database and tools, we analyzed 147 346 research articles, filtered 17 269 of them involving computational approaches and assigned each of them to one of six automatically derived topics: Molecular Pharmacology and Biomarkers, Molecular Virology, Epidemiology, Healthcare, Clinical Medicine and Clinical Imaging. Finally, guided by our categorization and scoring system, we reviewed the most relevant literature within each topic, with a special focus on the computational aspects of each study..

In the following, we describe both the CSCoV framework and the most relevant literature about COVID-19 involving computational approaches at various extents. The entire database, including categorization and prioritization scores, is publicly available together with the used computational models [111]..

We systematically collected COVID-19 related studies from four different sources (see Figure 1): PubMed for articles published in journals and arXiv, bioRxiv and medRxiv for preprint articles, gathering an initial broad collection of 147 346 papers. Studies involving computational approaches were selected based on 83 manually curated keywords appearing in the abstracts (see Supplementary Methods). We thus obtained a total of 17 269 papers, including 12 408 journal articles and 4861 preprints. The studies were published in 1655 different journals or conferences (see Supplementary Methods for additional details). Figure 2A shows a summary of the collected articles against publishing time. Some of the preprint articles originally appeared before the pandemic and have been subsequently updated for their potential application to the COVID-19 crisis. Novel preprints started to appear in January 2020, while the first journal articles date back to February. Expectedly, the ratio of journal articles versus preprint articles increased over time. On the other hand, for more than 60% of the preprints, we were not able to identify a corresponding journal publication after 70 weeks (Figure 2B) from its appearance online. Detailed statistics concerning the articles from each source are reported in Figure 2B..

Publication timeline of all the papers in the CSCoV database. (A) Number of articles appeared weekly since January 2019 divided by source. (B) Fraction of preprint articles that eventually appeared also in journals as a function of the number of weeks from their appearance online. C) Tabular summary of the number of articles currently included in CSCoV, grouped by source and publication status..

The CSCoV database is regularly updated. Each update includes both new articles and the corresponding analytical results described in the following..

In order to categorize all the collected articles into topics, we trained a latent dirichlet allocation (LDA [20]) with all the paper abstracts. LDA is a generative probabilistic model that aims at modeling each document from a given collection as a mixture of latent topics, which are in turn defined by a set of words. Once the topics are obtained, each document can be assigned to one of them..

Our final solution identified six topics: Healthcare, Epidemiology, Clinical Medicine, Molecular Pharmacology and Biomarkers, Molecular Virology, and Clinical Imaging. Figure 3A summarizes the results. In the figure, the entire collection is visualized as a two-dimensional (2D) map where each point represents an article colored by the assigned topic, and similar articles based on the extracted keywords appear close to each other (see Supplementary Methods for further details). The top 10 keywords for each topic are reported in Figure 3B. Topic names were assigned based on the top keywords observed after multiple runs of the LDA algorithm..

Categorization of articles in the CSCoV collection. (A) 2D visualization of the database. Each point represents an article, points proximity reflects article similarity, colors represent the extracted topic as reported in panel B. (B) Top 10 keywords in article abstracts identifying each of the six extracted topics. (C) Number of articles in CSCoV by topic..

In the map, the ‘Molecular Pharmacology and Biomarkers’ and ‘Molecular Virology’ topics lie especially close, which is expected based on drug and vaccine development efforts that make large use of the viral sequence. Interestingly, ‘Epidemiology’, ‘Healthcare’ and ‘Clinical Medicine’ are found next to each other, in a sequence that appear to arrange articles from the general population to the single patient perspective. Finally, articles in the ‘Clinical Imaging’ cluster, which are consistently driven by established Deep Learning approaches (see Subsection 3.7) constitute a well-characterized group on their own, expectedly placed next to the ‘Clinical Medicine’ cluster..

The relative number of articles across topics and sources also confirms an overall meaningful categorization (see Figure 3C). As expected, papers included in the arXiv collection have their larger relative shares assigned to the ‘Clinical Imaging’ and ‘Epidemiology’ groups, which largely rely on machine learning and mathematical models respectively (see Section 3). Only a negligible number of arXiv preprints is assigned to ‘Clinical Medicine’. On the other hand, bioRxiv articles are almost exclusively assigned the ‘Molecular Pharmacology and Biomarkers’ and ‘Molecular Virology’ topics, with zero articles assigned to ‘Epidemiology’ or ‘Clinical Medicine’. This is in line with the policy that was enforced by the platform maintainers since the launch of medRxiv, which requires authors to submit epidemiology- and medicine-related articles to the new server. Indeed a complimentary situation is observed for medRxiv articles, which tend to be especially associated with the ‘Epidemiology’ topic and cover the largest share of ‘Clinical Medicine’ studies. Articles collected from the PubMed collection span all the six topics, although they appear to be disproportionately fewer in the ‘Epidemiology’ topic..

Collecting and categorizing 17 269 articles allowed us to obtain a meaningful general overview (see Figure 3) of the contribution provided by the research community to fight the pandemic relying on computational techniques. However, a detailed review of the published literature implies carefully reading each single article, which is only feasible through a collective, time consuming effort that is unsuitable for an emergency and rapidly evolving situation. We thus sought to establish an advantageous trade-off between extensively reviewing every articles and the urgency to timely identify the most impactful or promising research paths. To this aim, we developed additional tools to prioritize studies that are more likely to be especially relevant, as illustrated in the following subsections..

The navigation of the sheer number of research articles constantly produced by researchers is normally facilitated by the collective work of the scientific community, which gradually digests published literature and implicitly produces signals of interest and consensus. For example, article quality has been shown to be reflected by the number of citations received [154], which in turn correlates with the number of times the article is downloaded from a hosting web server [60]. Although such indicators have many known limitations, they are commonly used by researchers as heuristics to screen scientific literature [153]. We thus took advantage of available indicators to estimate article credibility. We were able to collect the number of citations for all the papers in our collection using the Semantic Scholar online platform [50], and the number of downloads for all the preprint articles by scraping the public statistics available at bioRxiv and medRxiv. The arXiv server does not release such information..

Although the number of citations and downloads can be highly valuable for article prioritization, it is of course scarcely available for newly published studies, which are also an important target of this review. Moreover, citations and downloads are distributed differently across time. In particular, the latter appears to be especially novelty-driven, while the former extends longer over the years [60], which adds to the task difficulty. For these reasons, we sought to gather additional time-independent metrics. In particular, since a relation between the article citations and authors reputation has been shown [23], we added author data to our prioritization system. Using Semantic Scholar, we collected the number of papers published and the number of ‘Influential citations’ (see Supplementary Methods) received by each of the authors in our entire collection, which amounts to a total of 171 106 queries. The obtained scores showed similar distribution across article sources (see Figure 4A). Moreover, when comparing scores of preprints eventually published in journals against preprints of similar age that never did, we observed the former to have higher scores than the latter (see Figure 4C). By factoring in all the collected meta-data based on rank statistics (see Supplementary Methods), we were finally able to derive a score for each paper and prioritize the entire CSCoV collection accordingly. As expected, score distributions may differ across topics (see Figure 4D), which, however, we analyze independently in this paper..

Article scoring to guide manual review. (A) Four different metrics are used, including article-related (number of citations and views) and author-related (number of published articles and citations received) scores. As shown, the scores have similar distributions across sources. (B) The article citation network is used to prioritize preprints together with their text contexts. It shows general concordance with the computed topics, as highlighted by colors. (C) Comparison of scores across two groups of preprints having similar size and age but differing in publication status. The scores for articles published in journals tend to be higher. (D) Scores are not significantly biased across topics..

Although we believe that the gathered metrics can greatly help to score the relevance of the studies in our collection, preprint articles need special caution. On one hand, it has been shown that article quality does not improve dramatically after a preprint article passes the peer-review process [16]; on the other hand, recent cases of poorly substantiated claims in COVID-19 studies that appeared on preprint servers have reminded the research community about the risks posed by the lack of proper peer review [86]. Therefore, with the aim of gaining further indication about the reliability of preprint publications, we developed a machine learning framework to predict the chances that each preprint would pass a peer-review process solely based on its contents. In particular, we fed a Deep Neural Network model with article abstracts, the full article citation network (see Figure 4B), and the topic scores previously described. Each node in the citation network represents an article in CSCoV, and there is a link between two nodes A and B if the article A cites the article B. The model learned to discriminate preprint-only articles from articles published in journals (area under the curve (AUC) = 0.76) according to a probability score (see Supplementary Methods). We used the predicted probabilities to provide an additional score to all the preprints in our database..

Once we established the CSCoV database, we sought to exploit this resource to identify the most significant contributions provided by the research community to the fight against the pandemic. Although we used our prioritization system as a guide, we did not follow it strictly. In particular, we extracted the top 100 articles from each topic and manually reviewed them. The resulting selected articles are therefore the result of a mediation between the CSCoV recommendation system and our best judgment. Given the breadth of this review and the special focus on computational aspects, an in-depth analysis within each topic from an application field standpoint falls out of our aims. However, we cited those specialized review articles that are available in CSCoV when relevant..

Computational methodologies used in the reviewed articles are diverse, ranging from mathematical model fitting to artificial neural networks. Although we will detail them in the next Subsection, general insights can be obtained by analyzing the keywords used to build the database. Figure 5-left reports a summary including the top 10 keywords recurring within each topic, showing the importance of omics data analysis for ‘Molecular Pharmacology and Biomarkers’ and ‘Molecular Virology’, statistical models for ‘Healthcare’ and ‘Clinical Medicine’, neural network models for ‘Clinical Imaging’ and mathematical models for ‘Epidemiology’. Nonetheless, the same methodologies can of course be found across all topics..

Left: association between topics and the most recurrent keywords used to select computational studies provides insights into the most used methodologies. Right: diverse ‘omics’ data types have been used across topics..

‘Omics’ data analysis, which was made possible by computational approaches, had an ubiquitous presence in COVID-19-related research. Figure 5-right reports an analysis of different omics data types across research topics. In particular, articles concerning ‘Molecular Virology’ were fundamentally driven by genomic data, while transcriptomics and proteomics approaches are also significantly present. ‘Molecular Pharmacology and Biomarkers’ is the cluster in which we observed the largest diversity of ‘omics’ data types, including transcriptomics, proteomics, genomics and interactomics. Expectedly, ‘radiomics’-related keywords emerged from the ‘Clinical Imaging’ cluster..

The next Subsection aims at establishing the beginning of the COVID-19 research endeavor according to our database. Further Subsections review the most relevant studies that we identified within each of the six topics in CSCoV. A general timeline of the main publications we reviewed is shown in Figure 6. Finally, the last Subsection proposes some of the latest preprint articles that could provide an especially relevant contribution in the near future..

Timeline of the most representative reviewed studies by topic (colored dots), together with major events (black dots) related to the COVID-19 pandemic..

Based on the CSCoV database, we identified when the first computational studies about COVID-19 started to appear. Although a significant number of papers started to be published in February 2020, several articles appeared even earlier. These studies represent the first response by the research community to the pandemic. Here, we will mention the majority of them. As expected, most of them first appeared as preprint articles..

A few articles in the CSCoV database predate the epidemic. However they were originally unrelated with COVID-19 and later updated during the pandemic, thus we did not consider them here. By looking at single article versions, we identified the earliest published study as a preprint appeared on 19 January 2020 [32], and later published as a peer-reviewed article on 18 February [29]. The study used a mathematical model to assess the basic reproduction number of SARS-CoV-2 at 3.58. A second estimation of 2.2 obtained through stochastic simulations was published on 24 January [133]. On 31 January, a third preprint showed the use of a Bayesian framework to infer the time-calibrated phylogeny and the epidemic dynamics, resulting in an effective reproductive number of 1.1 and a most recent common ancestor dated at 7 December 2019 [186]. Contributing to the heated debate about the origins of the virus, on 27 January a preprint article showed genomic proximity with bat coronaviruses and excluded a recent recombination event based on evolutionary analysis [122]. The article appeared in a peer-reviewed journal three months later [121]. Another confirmation about the bat origin hypothesis arrived on 2 February based on RNA sequencing data analysis [173]. One of the earliest studies concerning prevention measures appeared on 28 January, confirming the risk posed by asymptomatic transmission on the basis of computational simulations [142]. Also one of the earliest studies involving pharmacological measures appeared at the end of January, attempting virtual screening for drugs inhibiting the M protease of SARS-CoV-2 [94]. The article was published in a journal one1 month later [125]. Finally, by means of epidemiological modeling, another preprint article reported on the necessity of healthcare measures, including lockdowns and universal face mask wearing, to counteract possibly disastrous consequences of the pandemic [105]..

From the inception of the pandemic, the development of effective treatments and vaccines has been one of the main hopes to effectively fight it. In recent years, computational tools supported researchers both in the former [152] and in the latter [117]. During this pandemic, it has been proposed that further efforts should be directed toward the definition of reliable computational pipelines in order to be more prepared for the next one [51], particularly given the potential of AI-based approaches [192]. Many studies assigned to this topic do not focus specifically on the identification of treatments, but also on the elucidation of molecular biomarkers that underlie potential treatments or disease mechanisms. They also span multiple omics data types, such as transcriptomics, proteomics, genomics, interactomics and metabolomics (see Figure 5-right)..

One of the most promising approaches to cope with health emergencies is the repositioning of already approved drugs to quickly respond to new outbreaks. This specific topic has been covered by a number of reviews also included in our database [3, 192]. Computational approaches have been used to prioritize potentially effective small molecules in a variety of ways, such as using molecular docking simulations and network-based drug repurposing, even with ad hoc SARS-CoV-2-related software tools provided to the community [84]. Docking simulations have been used to propose the efficacy of statins [43], recently confirmed by clinical data analysis [61]. In another study, remdesivir was identified through molecular docking and proposed as a potentially effective treatment for its ability to target the RNA-dependent RNA polymerase (RdRp) [41]. The drug has later been approved by the US Food and Drug Administration, although recommended against by the World Health Organization (WHO) [100]. Among network-based computational approaches, on 16 March, one integrative drug repurposing methodology was published to discover potential drugs in interactomic approach [191]. A total of 16 repurposable drugs (e.g. melatonin, mercaptopurine and sirolimus) were prioritized and further validated in human cell lines and three potential drug combinations (e.g. sirolimus plus dactinomycin, mercaptopurine plus melatonin and toremifene plus emodin) were identified. Another study used a knowledge graph based on 24 million PubMed papers to identify 41 drugs, among which dexamethasone, a glucocorticoid whose efficacy has been confirmed in hospitalized patients [57] and niclosamide, an anthelmintic recently proposed for repurposing on the basis of its ability to suppress the calcium-activated ion channel TMEM16F activity [15]..

A number of in vitro studies used metabolomics and transcriptomics data with the aim of identifying novel therapeutics [52, 63]. For example, using metabolomics profiling, spermidine, mk-2206 and niclosamide were shown to exert antiviral effects in VeroFM cells [52], while transcriptomics analysis was used to identify imatinib and mycophenolic acid as inhibitors of SARS-CoV-2 in hpsc-derived lung organoids [63]..

Besides direct drug discovery, many computational applications have provided insights about related molecular mechanisms. For example, one study reported the use of machine learning with chemoinformatics data to classify drugs and predict target specificity [138]. Among others, the study classified chloroquine and its highly debated [107] derivative hydroxychloroquine as non-specific drugs. Structural and molecular modeling was used to further investigate the two molecules helping to understand their mode of actions [44]. Molecular dynamics simulations have also been used to study the binding mechanism of remdesivir to RdRp, suggesting that the small molecule could act as a SARS-CoV-2 RNA-chain terminator, thus stopping RNA replication [184]..

One of the biggest breakthroughs in fighting the pandemic has been the development of vaccines. The efficiency of computational approaches has been advocated as a means to speed up vaccine and therapeutic antibodies for the COVID-19 emergency [140]. Among the papers we found of particular significance, one used a combinatorial machine learning approach to evaluate and optimize peptide vaccine formulations [94]. Many other studies in this context focused on the identification of epitopes and on the essential understanding of COVID-19 immunological mechanisms (see Subsection 3.2.3). Another work used machine learning-based reverse vaccinology tools, namely Vaxign and Vaxign-ML, to predict vaccine targets, supporting that a cocktail containing structural and non-structural proteins can be effective through the stimulation of complementary immune responses..

A number of proteomic studies have been dedicated to the identification of epitopes. Based on a tool named VirScan, a high-throughput method to analyze epitopes of antiviral antibodies in human sera, 800 SARS-CoV-2 epitopes were identified, 10 of which were considered likely recognized by neutralizing antibodies. Furthermore, XGBoost was used to predict SARS-CoV-2 exposure from the output of VirScan [146]..

Besides high-throughput approaches, other studies focused on specific interactions. For example, using structural modeling, a specific conformation of CR3022, a neutralizing antibody isolated from a SARS patient, was demonstrated to be required in order for it to bind a cross-reactive SARS-CoV-2 epitope [179]. In fact, prior knowledge about the SARS-CoV virus has been largely exploited. In one study, detection of sequence homology has been used to identify conserved regions between SARS-CoV and SARS-CoV-2. Epitope prediction was then performed using BepiPred 2, a random forest, sequence-based algorithm and Discotope, which relies on structural modeling [56]. Finally, an interesting application of computational methods in animal modeling is also worth of mention. Using sequence analysis and structural modeling, it was possible to identify a panel of adaptive mutations in a mouse-adapted SARS-CoV-2 strain potentially associated with increased virulence [58]..

Understanding the pathogenicity mechanisms of COVID-19 is important for the development of effective drugs, vaccines and antibody therapies, or to characterize the disease. Many transcriptomics studies were conducted to elucidate infection risk and mechanisms by evaluating the expression of angiotensin-converting enzyme 2 (ACE2) in different organs, such as lungs, heart, kidneys, intestines, brain and testicles [7, 67, 120, 168, 181, 182]. Other studies use transcriptomics to analyze the immune response among COVID-19 patients to discover biomarkers. For example, release of excessive cytokine, such as CCL2/MCP-1, CXCL10/IP-10, CCL3/MIP-1A and CCL4/MIP1B were suggested as biomarkers for COVID-19 pathogenesis [118, 175, 193]. Transcriptomics analysis was also used to identify type I interferon deficiency as a biomarker of COVID-19 severity [62]..

Proteomic data analysis was also widely employed for biomarker discovery. For example, one study analyzed the cellular infection profile of SARS-CoV-2 on human cell-cultures using mass spectroscopy (MS). Central cellular pathways such as translation, splicing, carbon metabolism, protein homeostasis and nucleic acid metabolism were reported to be reshaped after SARS-CoV-2 infection. Moreover, two inhibitors, 2-deoxy-d-Glucose, which blocks glycolysis, and NMS-873, which affects protein homeostasis, were found effective against viral replication in vitro [12]. Another study also used MS to analyze phosphorylation and perturbations in protein abundance, suggesting inhibition of the p38, CK2, CDK, AXL and PIKFYVE kinases as antiviral mechanisms [14]. Biomarkers were also used for automatic classification. One study profiled plasma proteomics of COVID-19 cases and reported 11 plasma proteins as biomarkers for severity. Using a machine-learning-based pipeline, the authors found that plasma levels of ORM1, ORM2, S100A9, CRP, AZGP1, CFI, SERPINA3/ACT and LCP1/LPL were elevated in severe COVID-19 conditions, while levels of FETUB, CETP and PI16 were reduced [147]. Using a similar approach with multi-omics data, a preprint article highlighted the specificities of proteomic and metabolomic responses to COVID-19 in younger patients, identifying potential children-specific markers [162]. Besides MS, sequence and structural analysis approaches were also used for proteomic studies. For example, different cytokine profiling and inflammatory signaling after SARS-CoV-2 infection were described in this way [112]..

Finally, metabolomic data were also employed in a number of studies. For example, circulating lipids, such as phosphatidylcholine 14:0_22:6 and 16:1_22:6, and phosphatidylethanolamine 18:1_20:4 were identified as potential COVID-19 biomarkers [8]..

Unsurprisingly, articles identified as related to Molecular Virology appear next to the Molecular Pharmacology and Biomarkers cluster (see Figure 3), which make large use of sequence and structural analysis especially based on genomics data (see Figure 5-right). Molecular virology studies significantly marked the progressive understanding of SARS-CoV-2, with the most important contribution arguably being the already mentioned (see Subsection 3.1) sequencing of its complete genome in January 2020 (published in February 2020 [173]). Using RNA sequencing and phylogenetic analysis, the study also showed that the new virus is closely related to a group of SARS-like coronaviruses found in bats. Based on the growing collections of viral sequences in online repositories, it became soon possible to identify reliable RT-PCR targets by identifying conserved sequences across multiple strains [36] and develop the effective molecular diagnostic tools. In April 2020, proteomics study of human leukocyte antigen susceptibility map for SARS-CoV-2 [113] and high-resolution transcriptome and epitranscriptome map of the SARS-CoV-2 were also reported [81]. Strongly linked to pharmacological studies, molecular virology research played a pivotal role in helping to shed light on the virus origin, detect novel variants and track the local and global evolution of the pandemic, as summarized in the next Subsections..

On the same day in which results about the similarity of SARS-CoV-2 to other bat coronaviruses were published [173], another article appeared that analyzed the similarity of SARS-CoV-2 to SARS-CoV, with 79.6% sequence identity and the same cell entry receptor (ACE2) identified [190]. The highest similarity was found against another bat coronavirus, RaTG13, with 96% identity. Andersen et al. [4] summarized the notable genome features of SARS-CoV-2 as mutations in the receptor-binding domain (RBD)and having polybasic furin cleavage site and O-linked glycans. They discussed three theories on the origin of this virus, (i) natural selection in an animal host before transfer to human, (ii) natural selection in humans after zoonotic transfer and (iii) laboratory selection and inadvertent release outside. Based on the genomic features observed, they concluded the latter to be implausible. Based on a population genetics-phylogenetics approach, another study used the full sequences of 52 SARS-CoV-2 strains to analyze selective events that accompanied the divergence of SARS-CoV-2 from RaTG13, concluding that the two viruses are likely to share a common ancestor [19]. Moreover, Zhou et al. [188] found a new bat virus (RmYN02) with 93.3% sequence identity to SARS-CoV-2. Its spike protein contains an insertion of multiple amino acids at the S1/S2 cleavage site, which is also observed in SARS-CoV-2 but not other betacoronaviruses, pointing again to natural evolution. Using phylogenetic dating methods, Boni et al. [13] assessed the divergence between SARS-CoV-2 and RaTG13 to possibly have happened as early as 1969. They also concluded that, given the large number of existing bat coronaviruses and their mutation rate, global surveillance systems employing genomic tools to identify and characterize pathogens in human disease are highly needed. Despite the many studies based on the viral genomic sequence, the origins of SARS-CoV-2 are still a major source of public debate while we write [102]..

Another fundamental use of genomic analysis is to track ‘variants of concern’, which pose a serious threat both for their potentially higher lethality or infectivity, and for the unknown efficacy of existent vaccines in contrasting them [37]. On 9 March 2020, a study employed metatranscriptome sequencing of samples from patients and controls and found that the number of intrahost variants was as much as 51, with a median of 1–4 in SARS-CoV-2-infected patients [143]. This indicates the in vivo evolution of SARS-CoV-2 after infection. During this pandemic, several transmissive variants have been reported. For example, the variant B.1.1.7 was first detected in southeast England in September 2020 and quickly became the dominant lineage in the country. Through genome analysis, 17 non-synonymous mutations and deletions in B.1.1.7 were identified, 8 of which in the spike protein, including N501Y, occurring at a key contact residue of the RBD [128]. In December 2020, the variant B.1.351 was reported from Eastern Cape Province, South Africa and characterized as carrying nine non-synonymous mutations, three of which at key sites in the RBD (K417N, E484K and N501Y) [156]. The P.1 variant was first detected in north Brazil in December 2020, and three RBD mutations, K417T, E484K and N501Y, were also identified in this lineage [45]. The 501Y mutation, present in all of the three lineages, has been reported to potentially cause an increased transmission rate, up to 70% [40]. Variants of concern are still constantly monitored across countries in an attempt to anticipate novel threats [172]..

A constant effort is also being devoted to track the virus spread at the regional, national and global level since the first epidemic outbreak. In February 2020, Park et al. [123] analyzed the first COVID-19 case in Korea using phylogenetic analysis and found that it clustered together with other SARS-CoV-2 sequences reported from Wuhan. Subsequently, by fitting a molecular clock model, Zehender et al. [180] analyzed the viral sequences isolated from three patients in the first outbreak of COVID-19 in Italy and concluded that the virus was present in Italy weeks before the first case was reported in 21 February 2020. De Jesus et al. [77] analyzed six cases of early reports in Brazil by combining phylogenetic analysis with self-reported travel history. Their results suggested multiple independent importations from Italy at the beginning of the Brazilian COVID-19 outbreak, further contributing to understand the dynamics of the pandemic. In the meantime, nine viral genomes from early patients in the United States were sequenced and analyzed [46]. Through a combination of genome epidemiology and travel pattern analysis, it was found that coast-to-coast spread had occurred, thus highlighting an urgent need for national surveillance. On the other hand, Lu et al. [98], who analyzed 53 genomes from infected individuals in Guangdong, China, showed that the large majority of viral infections in the province were caused by multiple importations, thus concluding that the surveillance and intervention measures taken had been effective. They also recommended careful interpretation of phylogenetic trees built in the early phase of the pandemic and suggested that epidemiological information should be combined with genomic data for more reliable results. In this regard, a related study has been conducted by Lemey et al. [91], who integrated travel history data in Bayesian phylogeographic inference. The study analyzed 282 SARS-CoV-2 genomes, 64 of which included travel history data, concluding that more realistic spreading hypotheses and higher predictive accuracy could be obtained as compared to using sample locations only..

Although the ‘Molecular Pharmacology and Biomarkers’ and ‘Molecular Virology’ clusters discussed above mostly assume a molecular perspective, the remaining four clusters shift the focus toward the actual impact of the pandemic, from epidemiological considerations to individual patient care. Here, we review the main studies in the ‘Epidemiology’ cluster..

Understanding epidemiological features and transmission dynamics of the pandemic is crucial to inform intervention policies [183], such as coordinating screening and containment strategies, anticipating the viral spread, and ensuring optimal use of resources to reduce morbidity and mortality [78]. During the COVID-19 pandemic, governments across the world have relied on epidemiological models to help guide their decisions [1]. For example, results from a study by the Imperial College in early March 2020 significantly influenced the country’s response strategies [1, 47]. The following Subsections describe major studies in the areas of epidemiological parameters estimation and assessment of non-pharmaceutical interventions (NPI)..

Critical epidemiological parameters influencing the spread of a virus include the ability of sustained human-to-human transmission, the basic reproduction number \documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$R_0$\end{document}, and the incubation period. In order to estimate such parameters, a large variety of methods have been used, including susceptible, infectious and recovered models; phylogenetic analysis; statistical simulations; agent-based models; network models; etc. Nonetheless, their objectives and contexts are generally homogeneous, therefore we summarized all of them by systematically collecting methodologies, dataset details, specific applications and resource availability. All this information is summarized in Supplementary Table 4. The most relevant studies are discussed below..

During the initial phase of the COVID-19 outbreak, human-to-human transmission by a novel coronavirus was confirmed, also based on Sanger sequencing and phylogenetic analysis, in a family of six COVID-19 patients, only five of which had been in Wuhan between 29 December 2019 and 4 January 2020 [25]. Another research analyzed the first 425 confirmed cases detected in Wuhan based on parametric model fitting of epidemiological information, reporting evidence of human-to-human transmission among close contacts dating back to December 2019 [92]..

The basic reproduction number \documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$R_0$\end{document} is the average number of secondary cases generated by an infected person. Many simulations were conducted to estimate its value across different countries. Most early studies reported a mean \documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$R_0$\end{document} to be within the range of 2 to 3 using epidemic data from China [48, 92, 134]. However, another estimate based on a bats-hosts-reservoir-people transmission network model resulted in a value of 3.58 [30]. As the virus spread across Europe, further early \documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$R_0$\end{document} estimates were published from Italy (2.43–3.10) [39] and England (2.8–3.10) [96]. The value of \documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$R_0$\end{document} is studied continuously, as environmental and viral features evolve, and more data become available..

Another crucial epidemiological parameter is the viral incubation period i.e. the time interval between infection and occurrence of the first symptoms. Incubation period estimations impact important public health activities, such as active monitoring, surveillance and control [90]. Studies showed that the median incubation period for COVID-19 is approximately 5 days, which is similar to other coronaviruses, such as SARS and MERS [90, 92, 157, 183]. Moreover, the mean serial interval, that is the time interval between the first symptoms in the primary patient and the beginning of symptoms in the next infected patients, has also been studied. By analyzing 8579 cases from 30 provinces excluding Hubei in China, one early study found such interval to be slightly shorter than the mean incubation period, thus indicating a risk of asymptomatic transmission [183]. The ability of the virus to transmit without causing visible symptoms has been a prominent cause of its dramatic spread..

Epidemiological models have been widely used to estimate the efficacy of NPI, such as case isolation, contact tracing, social distancing and lockdowns [78]. As for the previous Subsection, we reported a detailed summary of the used approaches in Supplementary Table 4 and will discuss a selection below..

On 28 February 2020, based on a stochastic transmission model, it was reported that highly effective contact tracing and case isolation could be enough to control a new COVID-19 outbreak within 3 months, as long as less than 1% asymptomatic cases occur [66]. However, asymptomatic transmission was later estimated at 6% by another study concluding that only widely used digital contact-tracing apps could possibly control the epidemic [48]. Although digital contact-tracing apps have raised concerns about privacy issues, they are widely accepted by some of the countries that achieved the best results at flattening the COVID-19 cases curve [72]. On this subject, Keeling et al. [79] conducted a detailed survey including information on social encounters from 5800 UK respondents, coupled with predictive models of contact tracing and control. The study concluded that the UK definition of contact as a permanence of at least 15 min within 2 meters is appropriate. However, according to the study, it also places a significant burden on health services, thus timely case detection and quarantine remain necessary to ensure the success of contact tracing..

Limitations to social activities to reduce contacts have also been widely studied and adopted. Measures like school and workplace closures or limiting gatherings have reduced the risk of overwhelming the health systems and bought more time for treatment and vaccine development, although at the cost of economic downturn [5]. For this reason, assessing the benefit-cost ratio of each intervention has been an objective of paramount importance, and many research efforts have been devoted to it. For example, in March 2020 a preprint article reported a comparison between one-time and intermittent social distancing scenarios in the United States based on a mathematical model [82]. The study concluded that adoption of the former could have delayed the epidemic peak eventually exacerbating the load on critical care services. The study contributed to the debate on the actual implementation of social distancing measures, which can take diverse forms. Another study, for example, used an agent-based model to analyze the effects of self-isolation, and in particular its impact on intensive care unit (ICU) occupancy in Canada [145]. According to the study, even with a self-isolation ratio of 40%, the need for ICU beds would still exceed the total supply in the country, suggesting once again the need for multiple combined interventions. On the other hand, cautious but timely lifting of social restrictions is also necessary in order to reduce their social burden. Therefore, the consequences of lifting NPIs have also been thoroughly studied. Hoertel et al. [68], for example, used a stochastic agent-based model to simulate the COVID-19 epidemic in France and analyze the potential impact of lifting a national lockdown. Although the study found a rebound to be almost certain, it also concluded that other measures, such as social distancing, mask-wearing and shielding of vulnerable people would still prevent the overwhelming of the critical care services..

In our embedding, the next cluster of studies concerns public health and related services. One of the greatest dangers posed by the ongoing pandemic has been the overwhelming of the national healthcare systems, constituting the main rationale behind policies aimed at ‘flattening the epidemic curve’. Among the top papers in our collection, a significant number in the ‘Healthcare’ group were devoted to studying the psychological burden on healthcare workers (HCWs) and lay people, the digital technologies to speed up the response by the healthcare system, and literature mining tools aiming at keeping researchers and practitioners up to date with latest knowledge..

During the battle against COVID-19, HCWs played the role of front-line fighters. Many factors, such as the ever-increasing number of patients, the overwhelming workloads, the shortage of specific drugs or equipment, have contributed to place a significant psychological burden on them, prompting researchers to study such secondary effects of the pandemic. In our database, most articles on the subject collected data digitally through online surveys and analyzed them using logistic regression-based models. Given the uniformity of the approaches, we summarized the most representative ones in Supplementary Table 5, reporting the geographical area of each study, the number of individuals surveyed, the specific aim and the used method. We describe a few representative examples in the following..

In two studies, multivariate regression models were used to assess psychological impact on Wuhan HCWs based on 5062 [195] and 1577 [114] surveyed subjects respectively. Factors like concomitant chronic diseases, history of mental disorders and family members or relatives confirmed or suspected positive were found associated with stress, anxiety and depression. Conversely, social and professional support was confirmed to exert protective effects. The need for psychological support was also underlined by another study on 1257 HCWs in China, especially among women and nurses [87]. Similar results were also reported from other countries. For example, an online platform was used to gather data from 1379 HCWs in Italy [137]. The study concluded that younger age and female sex were associated with posttraumatic stress symptoms, depression, anxiety and high perceived stress. Frontline HCWs were associated with posttraumatic stress symptoms, while nurses and health care assistants were more likely to endorse severe insomnia..

Besides the direct psychological burden on front-line HCWs, the general public has also been psychologically affected by severe intervention measures such as isolation and social distancing, which impose changes in routines and may favor anxiety and depression [21]. Many studies have been conducted to assess their impact. For example, Mazza et al. [103] tried to identify risk and protective factors for psychological distress in Italy. Using an online survey platform, they collected data from 2766 individuals. Multivariate ordinal logistic regression highlighted an association between female gender, negative affect and detachment with higher levels of depression, anxiety and stress. In general, psychological effects of the pandemic may involve a complex system of factors, such as the fear of getting infected, the worry about socioeconomic costs, xenophobic attitudes, and compulsive checking and reassurance seeking [155]. Some of these conditions may be ameliorated not only by psychological interventions, but also through behavioral attitudes. One study found that physical activity following the WHO guidelines may be beneficial in this sense [97]. Finally, sentiment analysis has also been used to assess the emotional state of the public in response to the pandemic. For example, one study analyzed 105+ million tweets in six languages (English, Spanish, Arabic, French, Italian and Chinese) using deep learning language models to identify positive, negative and complex (like joking) expressions. They found that early tweets were dominated by a mixture of joking with anxious/pessimistic/annoyed feelings, which shifted toward positive states (optimistic, thankful and empathetic) as the pandemic came under control [185]..

Digital technologies in the public health response to the pandemic are being harnessed worldwide with diverse applications [18]. Also using online data collection and analysis platforms, initiatives such as the epidemic intelligence from open sources by the WHO aim at early detection, verification, assessment and communication of public health threats based on publicly available data [171]. Rapid response strategies have been proposed using mobile applications in diverse contexts, such as self-reporting through online surveys [2, 130], digital contact tracing through Bluetooth-based proximity detection [48], or even remote healthcare services. For example, one study demonstrated vital signs measurement based on a convolutional neural network (CNN) model including an attention module to analyze image data acquired from the device’s camera [95]..

The surge in COVID-19 research publishing has posed both the opportunity and the challenge of exploiting continuously updated scientific knowledge with the aim of timely implementing state-of-art interventions [42]. In this context, AI approaches have been widely applied to help identify relevant literature, including the present work. On the other hand, crowd-based manually curated approaches to create annotated literature datasets for machine learning algorithms have been proposed as well [71]. In this regard, one notable effort has been made to automatically produce and update the COVID-19 research dataset (CORD-19) database, which include 500 000 scientific articles directly or indirectly related to SARS-CoV-2 [164]. This dataset has been specifically created for researchers to apply natural language processing algorithms and develop information retrieval and hypothesis generation approaches. Toward this aim, the TREC-COVID initiative was launched to build a test set and assess the ability of algorithms to rank CORD-19 papers based on their relevance to COVID-19-related topics [135, 161]. Based on the CORD-19 dataset, other works constructed knowledge graphs [170], also with applications to drug discovery [165]..

Most studies belonging to the ‘Clinical Medicine’ cluster analyze data directly obtained from patients. They usually apply statistical analysis approaches, which are well assessed in medical literature and better suited in a context of low dimensional data. However, a number of studies also make use of omics data analysis (see Figure 5-right) mostly for the identification of biomarkers with clinical applications. For example, transcriptomics data were used to characterize critically ill patients leukocytes [139]; proteomics data were used to characterize SARS-CoV-2 neurotropism [160]; metabolomics data were used to identify prognostic biomarkers [38]. One study integrated all of these three data types to identify molecular markers in peripheral blood and plasma samples of COVID-19 patients [32]. Biomarkers identification is a common theme within the ‘Clinical Medicine’ cluster, as shown in the remainder of this Subsection..

The vast majority of the top-scoring papers in the ‘Clinical Medicine’ topic concerns the assessment of risk and the identification of risk factors for COVID-19 patients. Many of them use classical logistic regression-based methods on internally collected data from hospitals and clinics [94, 187], in one case even producing an online risk calculator for the public [76]. One notable study proposed an online platform for the collection of large pseudonymised health records from English subjects at the national level, accompanied by open source statistical data analysis software [169]. The tool identified being male, greater age, diabetes and severe asthma among the most prominent COVID-19 risk factors based on the health records of ˜17 000 000 English adults, including ˜11 000 COVID-19 patients. Concerning model complexity, it is worth mentioning one study that used an XGBoost model as a best-in-class approach to assess the performance of a generalized additive model combined with LASSO regression, which is more interpretable at the cost of slightly lower predictive power [83]..

As opposed to identifying risk factors, other studies have focused on investigating some of the known ones in particular. For example, one paper supports that low levels of vitamin D concentration, which have been a concern also linked to lockdown measures [24], has little effect on the risk of infection based on the analysis of clinical data for ˜348 000 patients, 449 of which had confirmed COVID-19 infection [64]. Other such studies have investigated risk associations to diverse factors, such as smoking status based on Bayesian meta-analyses [149], hyperglycaemia using logistic regression [125] and even generic variants through whole-exome sequencing analysis [159]..

Finally, among the highest rated papers in the ‘Clinical Medicine’ category, it is worth mentioning a systematic review, which underlines both the importance of prognostic models and the urgency to improve their reliability [174]..

Most other articles in the cluster are devoted to the identification of COVID-19 patients clinical signs and to the assessment of treatement efficacy. Of note, some articles dealing with clinical signs use imaging techniques like computed tomography (CT) [11, 173, 178]; however, they focus on the statistical analysis of manually extracted features, as opposed to direct computational segmentation or classification as described in Subsection 3.7..

Finally, our database picked up a few clinical trial studies that specifically refer to modeling tools. For example, a retrospective study on 13 981 patients with COVID-19 in the Hubei Province, China, based on a mixed-effect Cox model, found a reduction of all-cause mortality from 5.2 to 9.4% in the subgroup of 1219 patients treated with statins [186]. A living systematic review uses a Bayesian network meta-analysis of clinical data from 85 trials (at time of publication) to monitor treatment efficacy, confirming a large uncertainty in the outcomes of highly discussed drugs, such as remdesivir, azithromycin, hydroxychloroquine and tocilizumab [148]..

The area of Clinical Imaging conceptually falls under the broader field of Clinical Medicine. However, due to the large number of specifically dedicated papers in our database, most of them sharing Deep Learning techniques, they formed a well-characterized cluster on their own (see Figure 3). A number of studies in this area use the term ‘radiomics’ to refer to the computational extraction of features from biomedical images [74, 89] (see Figure 5-right). Thoracic computer tomography (CT) and chest X-ray imaging have played an important role during this pandemic as easily accessible tools to diagnose COVID-19, monitor therapeutic efficacy and assess patients for discharge. In China, for example, portable chest X-ray devices are used in point-of-care testing, especially to monitor immobile, critically ill patients on a daily basis [93]..

The general workflow of imaging-based diagnostics can be divided into three phases: pre-scan preparation, image acquisition, and disease diagnosis [196]. After raw data are acquired, images are stored in a picture archiving and communication systems. In the diagnosis phase, specifically trained radiologists inspect the images to assess the presence of COVID-19-related features. The integration of AI in the loop can help speeding up this step, potentially producing a significant impact in emergent situations..

Application of AI in CT imaging can be generally divided into two main tasks: segmentation and classification. In chest CT image segmentation, deep learning models are employed to extract a target region of interest (ROI), such as lesion and lung lobes, and quantify the corresponding morphological features. We summarized studies belonging to this category in Supplementary Table 6, which includes references, methodology, number of patients, target ROI, data availability and performance scores. We mention some of the most representative studies below..

One intriguing approach proposed a weakly supervised model, which embeds a generative adversarial network (GAN) model [54] within the segmentation framework. This model is trained to replace the lesion with normal features until the image is classified as generated from a healthy patient, thus implicitly learning abnormal morphologies. This allowed to perform effective training even with a single voxel-level annotated COVID-19 patient CT scan [176]. Another innovative study used both a novel preprocessing method and a novel deep learning model for segmentation and quantification. Specifically, in order to deal with training data shortage, the proposed framework included a CT scan simulator for generating new images by interpolating existing ones over different time points. Moreover, the 3D segmentation problem was decomposed into three 2D problems, significantly reducing complexity and improving accuracy, as demonstrated over multi-country, multi-hospital, and multi-machine datasets [189]..

Other approaches use human-in-the-loop strategies, in which radiologists correct the results of automatic segmentation, thus speeding up the learning process. One such example called VB-Net is based on a modified 3D CNN combining a V-Net [104] model with a bottle-neck structure [141]. Another one, called COPLE-Net, uses an adaptive self-learning framework with a noise-robust Dice loss that is suitable for noisy labels [163]. Finally, Chen et al. [31] designed a modified U-Net [136] model, achieving the highest performance among those we reviewed..

Besides segmenting ROIs, many studies have also been proposed to detect COVID-19 using chest CT images, reporting impressively high accuracy. As before, we summarized the main features of many top-scoring articles in this category in tabular form (see Supplementary Table 7) and mention some of them in the following..

Many studies employed segmentation models, such as U-Net [136] or its variations, to extract features before classification. This was the case for Gozes et al. [55] (U-Net) and Chen et al. [27] (UNet++ [194]), both of which also used a pre-trained ResNet-50 [65] model for classification, achieving 0.996 and 0.989 accuracy, respectively. Other works applied deep transfer learning models without using segmentation. For example, Jaiswal et al. [75] used a DenseNet201 architecture [70] and Pathak et al. [124] used a ResNet [65]. Among alternative approaches, Wang et al. [166] combined graph convolution models with convolutional neural networks and proposed a new model named FGCNet, which achieved 0.971 accuracy..

Due to the nature of X-ray images, segmentation is less used in this context. In fact, all the top papers in our database concerning X-ray imaging are devoted to classification tasks, aiming at COVID-19 diagnosis. Also, in this case, we produced a detailed tabular summary, which includes references, dataset details, learning model, application, data availability and accuracy scores (see Supplementary Table 8)..

Among the top-performing models, Ozturk et al. [119] built on a previous You Only Look Once architecture named DarkNet [132], achieving 0.981 accuracy. Another work by Brunese et al. [17] used a model based on VGG-16 [150], which yielded an accuracy of 0.980. A number of studies focus on overcoming data limitation as a fundamental prerequisite to improve classification performance. For example, a work by Khalifa et al. [80] employed GAN for data augmentation and ResNet18 [65] for classification, achieving an F1-score of 0.990. On the other hand, Rajaraman et al. [127] trained a custom CNN and a selection of ImageNet pre-trained models on publicly available X-ray images and then applied transfer learning on COVID-19 images achieving 0.990 accuracy. Finally, Nour et al. [115] used a 5-layer CNN model for feature extraction and other machine learning models such as k-nearest neighbor, support vector machine (SVM), and decision trees for classification. In their results, the combination of CNN model and SVM achieved the highest accuracy (0.990)..

In addition to diagnosis, automatic severity assessment has also been proposed through X-ray image analysis. Cohen et al. [35] created a geographic extent score (ranging 0–8) and lung opacity score (ranging 0–6) based on the evaluation from three experts, and used them to train a DenseNet model [70]. Their results show that the model can regress the two scores with 1.14 and 0.78 mean absolute error, respectively..

In order to systematically review the latest research trends, we extracted the most recent (March–May 2021), top-scoring preprint articles that were also predicted to pass a peer review process with the highest probability. By reviewing such articles, we observed a shift of focus toward the monitoring of emergent SARS-CoV-2 variants, the evaluation of approved vaccines efficacy in real-world settings, and the follow-up of patients to investigate post-COVID-19 syndrome. We report a selection of representative articles in the following. Regardless of our effort to select the most potentially impactful literature, the mentioned results need to be considered unconfirmed..

Based on sequencing techniques and bioinformatic analyses, several emergent variants of SARS-CoV-2 are being identified around the world (see Subsection 3.3.2). For example, variant P.3, carrying multiple mutations in the Spike protein, has been reported from the Philippines. These mutations could possibly impact the interactions of the Spike protein with the ACE2 receptor and neutralizing antibodies [9]. B.1.617 lineage is found to be the predominant clade in Maharashtra, India, with accumulation of convergent mutations [33]. Variant B.1.616 was identified in Western France. It is reported to have higher lethality and to be poorly detectable by RT-PCR on nasopharyngeal samples [49]. Besides, another study identified multiple N-terminal domain (NTD) and RBD mutations of SARS-CoV-2 associated with reduced antibody neutralization from an immunosuppressed patient with tacrolimus, steroids and convalescent plasma therapy [28]. It provides an evidence that immunocompromised patients with convalescent plasma therapy are potential breeding grounds for immune-escape mutants..

Despite the benefits of vaccine clinical trials, their accuracy is limited by subject recruitment restrictions and sample size [177]. Evaluation in real-world settings is therefore necessary to obtain more detailed safety and efficacy estimations [144]. One of the most urgent needs is the evaluation of vaccine efficacy against SARS-CoV-2 variants [10, 126, 129, 144], which has been the subject of several recent studies. This is obtained through data analysis of large clinical datasets against sequence variants. For example, researchers in Oxfordshire, UK evaluated the effectiveness of Pfizer-BioNTech BNT162b2, Oxford-AstraZeneca ChAdOx1 and immunity after natural infection, against the B.1.1.7 variant in 13109 HCWs [99]. They found that natural infection with detectable anti-spike antibodies and two vaccine doses both provide robust protection. Besides, better understanding vaccine adverse effects is also important, both to minimize their impact on patients and to cope with vaccination hesitancy [131]. Researchers in the UK surveyed 974 HCWs with prior COVID-19 infections and compared those with and without a COVID-19 history using two-way analysis of covariance and a logistic regression model to evaluate the adverse effects following BNT162b2 vaccination [131]. They found that previous infection in absence of long COVID symptoms (see next Subsection) was associated with an increased risk of self-reported adverse events among the respondents. Besides, researchers in India assessed the outcomes of 515 HCWs completed two doses of Covishiel ChAdOx1-nCOV and Covaxin BBV-152 vaccines using logistic regression [151]. Both showed good immune response after two doses, which is good news in the war against COVID-19..

A portion of COVID-19 patients continue to experience persistent symptoms after being discharged from hospitals. This condition is known as post-COVID syndrome or ‘long COVID’ [34, 53, 69, 101]. To better characterize the syndrome, a follow-up study was conducted with 958 non-hospitalized patients in Germany, mostly with mild COVID-19 symptoms [6]. The study assessed the predictors of long-term symptoms, finding that 12.8% of the patients were affected by shortness of breath, anosmia, ageusia and fatigue at four or seven months after infection. Another nationwide cohort study in Germany followed 8679 hospitalized patients and analyzed risk factors [59]. It found a considerable long-term mortality of 29.6% in all subjects and readmission rates of 26.8% among 6235 discharged patients. Coagulopathy, body mass index \documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}$\geq $\end{document} 40 and age were reported to be risk factors for 180-day mortality. Finally, a study compared the CpGs number, telomere length, and ACE2 and DPP4 expression between 117 COVID-19 survivors and 144 non-infected volunteers using pyrosequencing [109]. The results showed a significant telomere shortening (3.03–10.67 Kb) and ACE2 expression decreasing in the COVID-19 survivors..

The ongoing COVID-19 pandemic has impacted all aspects of society and ignited an unprecedented global research effort. With the last severe pandemic being the Spanish flu, which dates back to 1918, COVID-19 is the first one to occur in a digitized world. With computers being ubiquitously used in modern societies, they are also expected to constitute a novel tool to fight global health emergencies, providing faster data and knowledge sharing, advanced analytical tools, and more accurate forecasting capabilities..

In order to analyze the impact of computational applications to the ongoing pandemic from a scientific point of view, we built a large database of research articles covering diverse aspects of the emergency, but all sharing the use of computational tools. Due to the complexity of the constructed database, we in turn used computational approaches to guide our review. The main topics we identified i.e. Molecular Pharmacology and Biomarkers, Molecular Virology, Epidemiology, Healthcare, Clinical Medicine and Clinical Imaging highlight the fundamental role of computational applications in supporting critical activities such as scientific discovery, clinical practices and institutional decision making in diverse areas of the ongoing crisis. We believe that our approach guided by automatic collection, categorization and prioritization of research articles can help to deal with publication bursts that are expected during emergencies such as the COVID-19 crisis..

During the pandemic, computational approaches have been used at various extents, from facilitating statistical data analysis of large datasets and gain a better understanding of the rapidly changing situation, to the construction of sophisticated machine learning models for automating, accelerating and/or guiding biomedical tasks. For some applications, such as those within the fields of genomics or structural chemistry, computers are now established tools routinely used through well assessed and standardized analytical pipelines. In other areas, such as drug repurposing or vaccine development, they are widely used as tools for candidate prioritization or hypothesis generation. In clinical applications such as automatic diagnostics and prognostics, computational models proved to be potentially effective, although the special caution required by patient care warrants further assessment and development toward fruitful integrating within healthcare systems [174]. Simulations based on mathematical models have been widely used to forecast viral spread or the effect of NPI measures. Governments around the world have relied on the results of such models to make informed decisions with vast socioeconomic effects. The immense impact that mathematical modeling can have in this area prompts the scientific community to strive for more reliability and wise use of available data, which can be particularly fragmented and inconsistent at the beginning of a global health emergency [78]. In other areas, such as the assessment of treatments efficacy and risk factors, computational approaches have supported classical statistical analyses of large datasets collected and managed through digital platforms..

While we write, the COVID-19 pandemic still poses a global threat. Nonetheless, extraordinary successes have been achieved by the scientific community in understanding the SARS-CoV-2 mechanisms and countermeasures. The contribution of computational sciences in this endeavor has been remarkable. In this regard, we believe that the experience gathered during the COVID-19 pandemic should lay the foundation for objectives that reach beyond the end of the current crisis..

A software framework was developed to automatically collect 17 269 computational studies related to COVID-19 from multiple sources, including PubMed and preprint servers..

Using an AI model, articles were automatically categorized into clusters corresponding to six topics: Molecular Virology, Molecular Pharmacology and Biomarkers, Epidemiology, Healthcare, Clinical Medicine and Clinical Imaging..

All the studies were ranked using bibliometric information and a Deep Neural Network model was developed to predict the chance for preprint articles to pass peer review..

The developed framework was used as a guide throughout an extensive and detailed manual review, which demonstrates the huge impact of computational approaches during the COVID-19 global crisis..

Click here for additional data file..

The CSCoV database is publicly available from Zenodo repository: https://zenodo.org/record/5495823 [111]. The code used in the study is publicly available from the GitHub repository: https://github.com/SFB-KAUST/covid-review..

F.N. collected and categorized the articles. F.N. and X.X. reviewed the articles by topic. X.X. retrieved and reviewed the latest contributions. F.N., X.X. and X.G. wrote and reviewed the manuscript..

This work was supported by grants from KAUST under the award number BAS/1/1624-01, FCC/1/1976-18-01, FCC/1/1976-23-01, FCC/1/1976-25-01, FCC/1/1976-26-01, REI/1/4473-01-01, URF/1/4352-01-01, and REI/1/4742-01-01..


Francesco Napolitano is a research scientist at Structural and Functional Bioinformatics Group, Computational Bioscience Research Center, KAUST..


Xiaopeng Xu is a PhD student at Structural and Functional Bioinformatics Group, Computational Bioscience Research Center, KAUST..


Xin Gao is a professor at Computational Bioscience Research Center, KAUST and the principal investigator of Structural and Functional Bioinformatics Group..

