The COVID‐19 pandemic has led to a resurgence of the debate on whether host–parasite interactions should evolve towards avirulence. In this review, we first show that SARS‐CoV‐2 virulence is evolving, before explaining why some expect the mortality caused by the epidemic to converge towards that of human seasonal alphacoronaviruses. Leaning on existing theory, we then include viral evolution into the picture and discuss hypotheses explaining why the virulence has increased since the beginning of the pandemic. Finally, we mention some potential scenarios for the future..

Why has SARS‐CoV‐2 virulence increased since 2020? Has it reached an evolutionary dead end or will it become a harmless virus? In this review, we particulary highlight three potential scenarios for the future evolution of SARS‐CoV‐2: i) towards avirulence (if tranmission and virulence are independent), ii) towards a higher virulence that optimises its trade‐off with transmission (fully adaptive path), or iii) towards an intermediate virulence level following a path difficult to anticipate, shaped by the yet poorly known adaptive landscape (maladaptive virulence evolution).

.


Alizon, S., & Sofonea, M. T. (2021). SARS‐CoV‐2 virulence evolution: Avirulence theory, immunity and trade‐offs. Journal of Evolutionary Biology, 00, 1–11. 10.1111/jeb.13896

.

The year 2019 witnessed the emergence of one of the largest and fastest spreading pandemics ever, which had caused more than 80 million infections and claimed more than 1.8 million human lives throughout the world by the end of 2020 (World Health Organization, 2021b). In April 2021, the pandemic was still out of control in many countries all over the world. The causative agent was rapidly identified as a novel coronavirus and named SARS‐CoV‐2 (Gorbalenya et al., 2020). Its most likely origin is believed to be from viruses currently circulating in bat populations (World Health Organization, 2021c)..

Many reviews have been written on the evolutionary origin of the virus (Andersen et al., 2020; Boni et al. 2020) and on its genetic evolution since then (van Dorp, Acman, et al., 2020; Worobey et al., 2020). Here, we focus on the phenotypic evolution of infection life‐history traits and, in particular, on virulence..

When it comes to the negative effects of infectious diseases on their hosts, a set of related but distinct notions can be found in the literature: mortality, lethality, pathogenicity and virulence. Among the four, mortality is the only aspect that refers to the population (Bonita et al., 2006). The others are defined at the level of an individual. Lethality, or fatality ratio, is the probability for an infected host to die in a given context. For SARS‐CoV‐2, lethality was rapidly shown to be 10 times that of seasonal influenza and also to strongly depend on age (Verity et al., 2020). However, it is important to stress that this trait varies depending on access to healthcare infrastructure or treatment availability. Pathogenicity can be defined at the cellular level and characterizes some of the harmful interactions between the virus and host cells (Isenberg, 1988). Finally, virulence is defined as the decrease in host fitness due to the infection (Read, 1994). Contrarily to the other definitions, it has an evolutionary dimension because it involves the notion of fitness, which is notoriously difficult to measure. Overall, the choice of the most appropriate trait to measure to study virulence evolution should maximize measurement practicality and public health importance, but also, most importantly, trait values should affect infection fitness (Alizon & Michalakis, 2015)..

In the following, unless stated otherwise and to simplify the reasoning, we will consider the infection fatality ratio (IFR), which is the proportion of infected hosts that die from the infection, to be a proxy of virulence. At the individual level, it is the metric that has the most direct meaning to a wide audience; however, care must be taken at the population level because IFR strongly varies with age (O’Driscoll et al., 2020; Verity et al., 2020) (Figure 1a). This implies that the age pyramid of a country shapes the IFR, even if the latter is assumed not to depend on nondemographic conditions, for example health care (Figure 1b). Furthermore, host immunity introduces another dimension of variation that needs to be accounted for when estimating the IFR..

Individual SARS‐CoV‐2 infection fatality ratio (IFR) as a function of age (a) and population average IFRs in 8 countries according to their demography since 1950 (b). In panel b, counterfactual mean IFRs were obtained by weighting the age‐stratified IFR data from O’Driscoll et al. (2020) by the relative frequencies of age classes from annual age pyramid data compiled by United Nations (2019). Dots show the median values and shaded areas the 95% confidence intervals.

We first present the evidence for the evolution of SARS‐CoV‐2 virulence. We then explain why some predict the virus population will evolve towards avirulence, before explaining why current trends do not follow this expectation. Finally, we present some hypotheses for future evolutionary dynamics..

For nearly a year, there was little clear evidence of phenotypic variations that could be linked to virus genetics. Of course, as shown by in vitro experiments of deep mutational scanning (Starr et al., 2020), some mutations have strong effects and many decrease the affinity of the receptor‐binding domain (BBD) of the virus spike protein to the human ACE2 receptor so much that they are likely detrimental. An exception that proves the rule is the D614G substitution in the spike protein, which occurred independently in different lineages throughout the world and was shown to increase the affinity of the virus for the ACE2 receptor on human cells (Korber et al., 2020). This was associated with an increased transmission rate in some regions, although teasing apart this effect from genetic drift was difficult in some locations (Volz et al., 2020)..

The picture completely shifted at the end of 2020 with the emergence of what are now referred to as ‘variants of concern’ (VOC). To avoid confusion, unless stated otherwise, we will only use the term ‘variant’ to refer to virus strains that cause phenotypically different infections compared with a reference, ‘wild type’, strains. For some strains, this phenotypic effect may be suspected, for instance, if several epidemiological clustered cases are caused by virus lineages bearing some mutations suspected to have strong phenotypic effects. The potential VOCs are referred to as variants of interest (VOI) and closely monitored by health authorities. Less preoccupying variants are referred to as variants under investigation (VUI). We also use the term lineage to refer to all viruses that have a different genotype than the ancestral reference..

As mentioned above, the D614G mutation is associated with an increased transmission rate (Volz et al., 2020) and therefore can be considered as a VOC. A second VOC (see Table 1 for a summary) was detected in September 2020 in Kent (UK) because a high proportion of Thermo Fisher RT‐PCR screening tests were exhibiting an unusual pattern. Indeed, this assay contains probes targeting three areas of the SARS‐CoV‐2 genome (in ORF1, S and N). Although in a small proportion of tests, one of the probes sometimes failed to detect its target, laboratories were seeing rapidly increasing numbers of RT‐PCR tests that seemed positive but where the S‐gene was not detected. This phenomenon was referred to as S‐gene target failure (SGTF). The analysis of sequencing data confirmed that infections with SGTF were caused by viruses belonging to the same lineage (B.1.1.7). The striking surprise was that these bore much more mutations in their genome than expected given the substitution rate estimated so far, with several of them, such as the N501Y mutation and Δ69‐70 deletion in the spike protein, being already under scrutiny (Rambaut et al., 2020). The dense epidemiological survey in the UK was used to track the SGTF in positive RT‐PCR tests, and the statistical analyses identified a significant transmission advantage of what is now known as the α variant over the other lineages (Davies, Abbott, et al., 2021; Volz et al., 2021). The analysis of contact‐tracing data also identified a higher percontact transmission risk (Variant Technical group, 2021). Variant α spread all over the world, and similar transmission advantages were estimated in countries such as Denmark, Switzerland (Davies, Abbott, et al., 2021) or France (Haim‐Boukobza et al., 2021)..

Taxonomy and properties of the main SARS‐CoV‐2 variants detected to date.

B.1.427.

B.1.429.

Only variants with demonstrated phenotypic differences are shown. ‘Detection’ indicates the first country to report the variant, and ‘date’ indicates the date of the earliest sample known. ‘WHO’ (World Health Organization, 2021a), ‘pango’ (Rambaut et al., 2020), ‘GISAID’ (Elbe & Buckland‐Merrett, 2017) and ‘nextstrain’ (Hadfield et al., 2018) refer to the main nomenclatures. Mutations and deletions (Δ) in the spike protein compared with the first sequence from Wuhan (China) were obtained from outbreak.info (Latif et al., 2021). Mutations of concern are highlighted in italic..

A few months later, two analyses conducted in the UK detected a possible increase in the virulence of the infections caused by the α variant (Challen et al., 2021; Davies, Jarvis, et al., 2021). Care must be taken to interpret these results because many SARS‐CoV‐2 infections are asymptomatic, meaning that the case fatality ratio (CFR) can differ from the infection fatality ratio (IFR) (Verity et al., 2020). Indeed, the former quantifies the fraction of deaths among detected COVID‐19 cases (usually because they are symptomatic), whereas the latter estimates the fraction of deaths among all infected hosts. Logically, CFRs are greater than IFRs. However, as reported by both studies, the fraction of infections caused by 501.V1 is not higher when analysing data from a random sample of the population instead of symptom and contact‐oriented tests. This rules out the possibility that the variant might be causing an increased proportion of asymptomatic infections, which would bias the IFR estimate..

In summary, there is reasonable evidence that variant α, according to the World Health Organization's (WHO) terminology (World Health Organization, 2021a), has an increased transmission rate and an increased virulence compared with the wild‐type strains..

Also at the end of 2020, another lineage (B.1.351) was reported to spread rapidly in South Africa. Sequencing quickly revealed that it too bore a higher number of mutations than expected based on the mean molecular clock value (Tegally et al., 2020). Among these mutations, there was the N501Y substitution found in variant α, but also the E484K mutation, which is associated with immune escape (Cele et al., 2021). Evidence from other countries confirmed that what is now known as the β variant also has a transmission advantage over wild‐type strains. Its virulence remains less known, but its ability to evade natural host immunity and even some vaccine immunity is very likely (Hoffmann et al., 2021)..

A third major epidemic took place at the end of 2020 that suggested involvement in virus evolution. This epidemic was unexpected because it took place in Brazil and especially in the region of Manaus, where serological data suggested that, after a major health catastrophe, the cumulative incidence reached the theoretical herd immunity threshold (Buss et al., 2021). As for the other variants, genomic analyses again showed that the new epidemic was associated with a specific lineage bearing several mutations (P.1), including the N501Y and E484K substitutions (Faria et al., 2021). In this case, the analysis was able to detect a significant transmission advantage of what is now known as the γ variant, as well as an ability to reinfect hosts with natural immunity (Hoffmann et al., 2021)..

The last WHO VOC, now known as the δ variant, corresponds to the B.1.617.2 lineage. The oldest known sample dates from the end of 2020 and was collected in India, where the variant was associated with a major outbreak in spring 2021. Early analyses in United Kingdom, where it reached the majority of new contaminations early in 2021, suggest that the δ variant is associated with an increased transmissibility and, potentially, an increased risk of hospitalization, compared with the α variant (Public Health England, 2021; Scientific Pandemic Influenza Group on Modelling & Operational sub‐group, 2021). Early epidemiological results also suggest that this new variant may partially evade immunity (Bernal et al., 2021), especially in people with only a single vaccine dose (Bernal et al., 2021). Furthermore, the fact that the δ variant does not bear the N501Y and E484K mutations found in, respectively, all three and two previous VOCs illustrates the limits of SARS‐CoV‐2 convergent evolution (Martin et al., 2021) and challenges the current existence of strong genomic bottlenecks..

Many VOIs have been reported worldwide World Health Organization (2021a) but, by definition, their phenotypic effect on infection life‐history traits remains limited, if not unknown. Note that one of these VOIs, CAL.20C (pango lineages B.1.427 and B.1.429), which was first detected in California (USA), was shown to have a slight transmission advantage (Zhang et al., 2021). In France, variant 20C/H655Y (pango lineage B.1.616) appears to have a pronounced tropism for lower respiratory tracts and seemed difficult to detect using classical nasopharyngeal swabs (Fillatre et al., 2021)..

In the context of the ‘test, trace and isolate’ strategy implemented by many countries, this latter VOI raises speculations about a potential transmission‐detection trade‐off. Indeed, specializing in colonizing the epithelium of the upper airways is expected to yield a transmission gain for the virus (Harrison et al., 2020; Wölfel et al., 2020) but it also increases the probability of detection using nasopharyngeal swabs. If case isolation measures are strong (Grassly et al., 2020), such a tropism can greatly affect further virus transmission. Therefore, if the selection pressure exerted by nasopharyngeal mass testing measures is significant enough, the evolution of a virus tropism towards the lower respiratory tract and, hence, an increased virulence, could be favoured if the decrease in detection probability compensates the decrease in transmission rate..

What is likely is the replacement of the ancestral lineages by variants with a significantly different genetic background is likely going to set a new stage for the SARS‐CoV‐2 fitness landscape (Martin et al., 2021). In other words, mutations that had little effect or were deleterious in the ancestral genome may prove to be adaptive. Furthermore, the immunization of the population is introducing a coevolutionary dimension, which makes the effect of specific mutations difficult to anticipate..

Theory stemming from Theobald Smith's law of declining virulence more than a century ago (Méthot, 2012) postulates that we should expect SARS‐CoV‐2 to evolve to cause avirulent infections in humans. Although this reasoning is frequently invoked for many infectious diseases, in the current case it is reinforced by the fact that the most common, and seasonal, coronaviruses we know cause little mortality (Gorbalenya et al., 2020)..

A model by Lavine et al. (2021) elegantly explains why SARS‐CoV‐2 could become a seasonal virus causing little mortality at the population level. The essential ingredients of their reasoning are that (a) the IFR strongly depends on age, and (b) the immunity that prevents severe disease (i.e. anti‐virulence immunity) is long‐lasting. What they show is that such an age‐structured system can converge in a matter of years towards a steady state where individuals are infected as children, which allows them to build an immune response with very low mortality. This immunity prevents severe symptoms (i.e. COVID‐19) when infected as adults. The time to converge towards this state depends on how fast the virus spreads, which itself depends on the transmission rate of the virus and the intensity of transmission‐blocking immunity. The authors also find that this trend is not expected for coronaviruses such as severe acute respiratory syndrome (SARS) and Middle‐East Respiratory Syndrome (MERS) because their virulence in children is so high that it would lead to massive mortality at the population level. Importantly, this reasoning focuses on mortality (i.e. a population‐level variable) and that it does not require any virulence evolution per se (the IFR remains unchanged for a given age)..

When virus evolution is allowed, the existence of multiple SARS‐CoV‐2 infection sites can be used to build scenarios consistent with the avirulence hypothesis (Smith, 1887). To simplify, when this virus infects lower respiratory tracts (LRT), it faces a strong immune response, it causes more damage to host tissues, and its transmission to new hosts is limited. Conversely, in the upper respiratory tract (URT), infections face a weak immune response, cause minor damage to the host and achieve high transmission rates (Harrison et al., 2020). The virus can also infect cells in the intestinal tracts (Xiao et al., 2020). This is thought to be associated with diarrhoea, but the transmission potential is unknown (Guo et al., 2021). Therefore, one expects natural selection to favour SARS‐CoV‐2 mutants that specialize in infecting URT because it maximizes transmission and, more importantly, because immunity will build up in the LRT, either through recovery from natural infection or from vaccination..

Given that the ACE2 receptor, which is SARS‐CoV‐2's entry point into the cells, is more expressed in the URT than in the LRT, and given that many mutations in the spike protein increase its affinity for ACE2 (Ziegler et al., 2020), the fixation of the D614G mutation could be interpreted as an evolutionary trend towards avirulence. However, another interpretation is that this increased affinity for the receptor might not be traded‐off for a lower ability to exploit the LRT, therefore combining increased transmission rate and virulence. The latter seems more likely given that variant α represents the majority of the genomes uploaded on the GISAID platform since February 2021, meaning that, so far, the average virulence of the world population of SARS‐CoV‐2 has increased..

When a parasite spills into a new host population, it is often maladapted because there are known trade‐offs relating to host exploitation. This host specialization was actually used to create live‐attenuated vaccines by performing serial passages of a parasite through cell cultures, or chicken eggs, or another host, to generate less virulent strains that could be used for vaccination (Ebert, 1998). As we will see later, when it comes to virulence, there is no rule for maladaptation: the virus can be nearly avirulent if it fails to exploit human cells, but it can also be extremely virulent if it causes massive immunopathology, for example via the activation of cytokine storms. Illustrating these differences in maladaptation is difficult because, ideally, it would require finding different strains of the same parasite species that are maladapted in different ways. In the case of coronaviruses, two extreme examples could be MERS, which is extremely virulent in humans (Lessler et al., 2016), and feline coronavirus, which cannot infect humans (Sykes, 2014). In the case of SARS‐CoV‐2, evidence points more towards maladaptation with high virulence given the physiopathology of the infection (Tay et al., 2020)..

Maladaptation to a novel host can account for SARS‐CoV‐2's initially large virulence but it does not explain why it is not decreasing rapidly. A first possibility is that natural selection cannot act on SARS‐CoV‐2 virulence, for instance, because of a lack of genetic variability (Dearlove et al., 2020; van Dorp, Richard, et al., 2020). RNA viruses have to balance large mutation rates and strong genomic constraints, and it could be that there is no viable way for the virus to decrease the immunopathology it causes (Belshaw et al., 2008). Note that, as pointed out earlier, these constraints could be changing and the fixation of many mutations in the variant lineages could have reshaped the fitness landscape (Martin et al., 2021)..

Even if we assume that mutants with a comparable transmission ability and a lower virulence than the wild‐type strains could emerge, it is still possible that they would not have a clear advantage in terms of natural selection. Indeed, it is essential to account for the life history of the infection (Figure 2). Although the IFR is approximately 10 times that of seasonal influenza, severe symptoms and hospital admission are a minority and, when they occur, take place on average 14 days after infection (Sofonea et al., 2020). By that time, contagiousness is virtually negligible since 95% of the transmission events seem to occur between 2 and 11 days after infection (He et al., 2020). More generally, the symptoms of an index case appear on average 1.3 days after the mean transmission time to her/his ‘infectee’ (Alene et al., 2021). Therefore, from the virus perspective, harming the host is not very costly as it will have little effect on its epidemiological fitness, which, if we leave aside host immunity, can be approximated through the basic reproduction number (R
0), that is the average number of secondary infections caused by an infected person during her infectious period. As explained by Day (2003), this idea echoes classical results from life‐history theory, especially the evolution of ageing, where traits that have deleterious late in life tend not to be selected against..

Semi‐quantitative clinical, epidemiological and diagnostic individual history of COVID‐19 infections. The clinical timeline shows the distribution function of the incubation period (time from infection to onset of symptoms), the vertical bar representing the median (McAloon et al., 2020). The breakdowns into clinical phases are exposed are presented with respect to the median symptom onset date (Bouadma et al., 2020; Nalbandian et al., 2021; Polak et al., 2020). The asymptomatic fraction on the top is that estimated by Byambasuren et al. (2020). The epidemiological timeline represents the probability density of the generation time estimated by Ferretti et al. (2020), with the vertical bar showing the median. The latency is the time between infection and the onset of contagiousness. The diagnosis timeline indicates the positivity kinetics of nasopharyngeal RT‐qPCR tests. Following the estimates from Hellewell et al. (2021), more than 50% of cases are positive in the central green band and more than 5% in the peripheral light green bands. Antigenic and serological (immunoglobulin (Ig) M and G) test positivities are shown for qualitative purposes following the estimates from Mercer and Salit (2021).

Since the early 1980s, an explanation for the maintenance of virulence is that the latter can be correlated with traits that are adaptive for the parasite (Anderson & May, 1982; Bremermann & Pickering, 1983; Ewald, 1983; Levin & Pimentel, 1981). For instance, as shown in the case of HIV, strains that cause the most virulent infections tend to be the more transmissible, and the correlation between the two traits could be mediated by the virus load (Fraser et al., 2014). According to such a transmission–virulence trade‐off hypothesis, the exact shape of the relationship between the two traits determines the level of virulence that maximizes the epidemiological fitness of the virus (Alizon et al., 2009). The latter can be seen, in the simplest setting, as the number of secondary infections caused by an infected host. Note that the transmission–virulence trade‐off is restrictive and that other infection life‐history traits should be taken into account to capture the whole life cycle of the virus (Alizon & Michalakis, 2015). In the case of SARS‐CoV‐2, it may be relevant to investigate virulence–recovery trade‐offs (i.e. more virulent strains would have longer infectious periods (Anderson & May, 1982)) or transmission–recovery trade‐offs (if strains that cause shorter infections have higher transmission rates (Alizon, 2008)). Another life‐history trait that could matter is the time until symptom onset because infectiousness of asymptomatic hosts is a key driver of epidemic spread (Fraser et al., 2004). Trade‐offs involving this trait have been less studied but Saad‐Roy et al. (2020) investigated the evolutionary consequence of a trade‐off between the duration of the asymptomatic period and the transmission rate, and, more generally, Sorrell et al. (2009) studied the evolution of asymptomatic infections, which could have implications for SARS‐CoV‐2 given that some individuals appear never to exhibit any symptoms..

In the case of SARS‐CoV‐2, some (limited) evidence suggests that increased virulence can be associated with variations in other life‐history traits that are adaptive for the virus. For instance, a contact‐tracing study showed that individuals with higher viral loads tend to infect a larger proportion of their contacts (Marks et al., 2021). Furthermore, longitudinal follow‐ups show that patients who develop more severe infections tend to have higher virus loads (estimated via the cycle threshold values of RT‐qPCR tests) for a longer time (Néant et al., 2021). Therefore, it could be envisaged that an increased virus load could lead to both increased virulence and contagiousness. Finally, there are data suggesting that the α variant is causing longer infections (Cosentino et al., 2021; Elie et al., 2021)..

The adaptive virulence hypothesis is illustrated in Figure 3b, which assumes a transmission–virulence trade‐off. If the virus population is sitting on the trade‐off curve and if the virulence is below the level that maximizes the viral fitness, any increase in transmission rate requires an increase in virulence. However, the trade‐off curve only indicates a constraint and, as we saw above, the virus population could very well be located far from the optimum (Figure 3c). In this case, short‐term evolutionary dynamics are more difficult to anticipate because first, we do not know how far the virus population is from the trade‐off curve (there are many ways to be maladapted) and second, what matters in the short term is the shape of the local fitness landscape. To take a verbal example, one could imagine that a mutant with a virulence and transmission rate could have higher epidemiological fitness (or R
0) than its strain of origin, even if the virulence of this strain is already larger than that of the evolutionary stable strategy (the black dot in Figure 3c). In the other scenarios, such a mutant would most likely have a small R
0 than its strain of origin (Figure 3a) or be a biological aberration (i.e. fall into the nonviable area in Figure 3b)..

SARS‐CoV‐2 virulence evolution scenarios. (a) More virulent strains are always less fit, (b) virulence and transmission rate are correlated and strains are well‐adapted (i.e. they sit on the trade‐off curve), and (c) same as b but strains are currently maladapted (far from the trade‐off curve). Dashed blue lines show hypothetical transmission–virulence relationships, shaded blue areas the inaccessible state space and black dots the trait combinations maximizing invasion fitness in a naive population (R
0). Dashed arrows show potential evolutionary trajectories. Virulence and transmission rates are in arbitrary units. The virulence and transmission rates of the α and γ variants are currently largely unknown. For the γ variant, the transmission rate appears to be higher (Buss et al., 2021). Viruses can emerge anywhere in the white area, even if they cause virulent and poorly transmissible infections as B.1.616 (Fillatre et al., 2021). For further details about the variants, see Table 1
.

More generally, nonequilibrium dynamics can explain the persistence of virulent strains, at least transiently. As clearly shown using the Price equation formalism, in the short term, and under the assumption of a correlation between virulence and transmission, more virulent strains tend to be favoured early in an epidemic (Day & Proulx, 2004). The underlying process, which has been shown experimentally using bacteria and phages (Berngruber et al., 2013), is that in an expanding population, an increase in birth rate (or, in the case of an epidemic, transmission) bring more benefits than the same increase in longevity (or infection duration). When the population shrinks, which is the case after an epidemic peak, longevity then becomes more important than birth rates. The essay by Day et al. (2020) discusses these nonequilibrium dynamics in the context of the COVID‐19 pandemic showing, for instance, that the strongest selective pressure in the initial stage of the epidemic is for increased transmission rate. They also expect selection to favour viruses that tend to be less virulent and cause less symptomatic infections..

The evolution of variants has changed the nature of the SARS‐CoV‐2 pandemic by showing that strong phenotypic evolution is possible for this virus. Interestingly, the difficulty to label these variants is a direct illustration of the ongoing evolutionary dynamics. With the emergence of the D614G mutation in many lineages around the world (Volz et al., 2020), it was tempting to define VOCs through ‘mutations of concern’. This was further supported by the parallel evolution of the N501Y mutation in the α, β and γ variants or of the E484Y mutation in the β and γ variants. However, it is also troubling that VOC all appear to bear a higher number of mutations in their genome than other lineages (Table 1). Furthermore, except for D614G, mutations of concern such as N501Y or E484K seem to be advantageous only in some generic backgrounds. For instance, in the UK, the B.1.1.7 lineage (i.e. the α variant) bearing the E484K mutation appears to have a smaller epidemiological fitness than the β or γ variants. Current trends suggest that epistatic interactions may now dominate SARS‐CoV‐2 evolution and that mutations with effects similar to D614G could be rare. However, it may be hazardous to use past evolutionary trends to anticipate SARS‐CoV‐2 evolution since the fitness landscape that viruses can explore changes as the virus population evolves. For instance, the fixation of the N501Y mutation in the genome has been suggested to deeply affect the fitness landscape compared to that inferred from the original strain detected in Wuhan, China (Martin et al., 2021)..

The epidemiological scenario by Lavine et al. (2021), which does not include virus evolution, relies on the assumption that host immunity against symptoms is robust. Unfortunately, field epidemiological data suggest that this might not be the case for the β and γ variants (Abdool Karim & de Oliveira, 2021), and, perhaps, for the δ variant (Bernal et al., 2021). For some vaccines, this immunity appears to be more robust but will this still be the case for future variants? Currently, the greatest unknown appears to reside in immune escape, which can jeopardize the avirulence scenarios. Indeed, with immune escape, absolute fitness (i.e. R
0) should be abandoned in favour or relative fitness measures since the ability of a strain to spread will depend on the immunity of the population, that is on the nature of the strains that are and that have circulated in the past (Lion & Metz, 2018)..

With the diversification of SARS‐CoV‐2, the role of multiple infections will likely increase, and these are known to affect virulence evolution (Alizon et al., 2013). Even for short respiratory infections, some infection patterns, in the sense of Sofonea et al. (2017), such as ambinfection, where genotypes are always co‐transmitted, could matter (Lythgoe et al., 2021). Furthermore, the alleviation of nonpharmaceutical interventions implemented to control the pandemic will allow other respiratory infections to spread again. This is particularly true for influenza virus. Here, the evolutionary dynamics are even more difficult to foresee because these involve coevolution between different parasite species and heavily rely on the nature of within‐host interactions (Choisy & de Roode, 2010; Kamiya et al., 2018)..

In the long run, immune escape strategies may not be viable for coronaviruses because they impose too many constraints on their genomes (Belshaw et al., 2008). Such reasoning largely rests on our knowledge of the current seasonal coronaviruses, for which large pandemics of immune escape mutants have not been recorded. However, recent results from a time shift experiment conducted using human serum collected from 1985 and 1990 and synthesized spike proteins of the seasonal alphacoronavirus 229E from 1984 to 2016 found that our immune system appears to be less efficient at recognizing ‘future’ coronaviruses (Eguia et al., 2021). This would mean that regular reinfections by seasonal coronaviruses may not just be related to their ability to infect URT, where the immune response is limited, but could also depend on antigenic evolution of the viral spike. Furthermore, an important lesson from this pandemic is that extreme care should be taken before comparing SARS‐CoV‐2 to other viruses, even human coronaviruses. Indeed, this has led to underestimating the transmission before symptoms onset, the airborne transmission and even the magnitude of the pandemic. One of the most recent seasonal coronaviruses is thought to have emerged in the 1950s (Forni et al., 2017). As suggested by Figure 1b, even though half a century ago the age pyramids were different in many countries, the IFR of a coronavirus with a virulence pattern similar to SARS‐CoV‐2 would not have gone unnoticed, although the baseline immunity in the population to viral infections could have been higher at the time due to higher exposition to infectious diseases. This suggests that the virulence of the new virus, which is lower than SARS‐CoV and MERS, with increased transmission before symptoms, but higher than the seasonal coronaviruses, is the worst in terms of population mortality. Again, basing our strategies on immune escape patterns from known coronaviruses can be extremely hazardous..

The high virulence of SARS‐CoV‐2 and its evolution makes it essential to closely monitor this trait. Beyond the definition issues raised in the introduction, a major difficulty for this resides in the proportion of asymptomatic or paucisymptomatic infections, meaning that the IFR is much more difficult to measure than the CFR. To minimize the biases in virulence estimation, the random testing strategy implemented in countries such as the UK seems ideal because it allows controlling for the proportion of variants (Challen et al., 2021; Davies, Jarvis, et al., 2021). International coordination for such random testing appears to be particularly urgent, especially in the context of vaccination (Kennedy & Read, 2020)..

On a more positive note, the successful implementation of RNA vaccines does change the dark picture painted by immune escape risk. Indeed, these vaccines theoretically have the potential to follow the coevolutionary race with the virus, at least whereas its genetic diversity remains limited (Dearlove et al., 2020), and this could prove decisive, given the evolutionary rates observed so far. However, we also know that virulence‐blocking vaccines tend to select for strains that are more virulent in nonvaccinated hosts (Gandon et al., 2001). More than ever, we need to monitor virus evolution to avoid an arms race between SARS‐CoV‐2 and public health policies (Kennedy & Read, 2020; Van Baalen, 1998)..

The authors declare that there is no conflict of interest..

The peer review history for this article is available at https://publons.com/publon/10.1111/jeb.13896..

We thank Yannis Mickalakis and the ETE team for discussion..

